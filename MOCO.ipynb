{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in this notebook we will implement MOCO paper:\n",
    "#https://arxiv.org/pdf/1911.05722.pdf\n",
    "#CNN architecture we change, but MOCO loss function is the same, and training is the same\n",
    "#we use 5 different data gmentations (rotations, blur, color distortion, cropping and resizing) for defining the positive samples\n",
    "\n",
    "#training is done on 1 GPU, training setting are:\n",
    "#1. Use the entire training data to learn the representations.\n",
    "#2. Once the representations are learned, use a linear and logistic layers and retrain with 10-50% of supervised training data.\n",
    "#3. Experiment with two different sizes for the encoder dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "\n",
    "from functools import partial\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'config' from '/home/lisa/bhartendu/adrl/A3/config.py'>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "import models\n",
    "importlib.reload(models)\n",
    "from models import  pentaClassifier, binaryClassifier, baseClassifier\n",
    "\n",
    "\n",
    "import config\n",
    "from config import cfg\n",
    "importlib.reload(config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed\n",
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "# Torch RNG\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HYPER - PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = 'results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.06\n",
    "epochs = 200\n",
    "batch_size = 512\n",
    "schedule = [120, 160]\n",
    "wd = 5e-4\n",
    "cos = True      # cosine lr schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "moco_dim = 512\n",
    "moco_k = 4096\n",
    "moco_m = 0.99\n",
    "moco_t = 0.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_splits = 8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data-loader\n",
    "\n",
    "#### Adapted from pytorch code of Contrastive learning libs: http://github.com/zhirongw/lemniscate.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "class CIFAR10Pair(CIFAR10):\n",
    "    \"\"\"CIFAR10 Dataset.\n",
    "    \"\"\"\n",
    "    def __getitem__(self, index):\n",
    "        img = self.data[index]\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            im_1 = self.transform(img)\n",
    "            im_2 = self.transform(img)\n",
    "\n",
    "        return im_1, im_2\n",
    "\n",
    "# train_transform = transforms.Compose([\n",
    "#     transforms.RandomResizedCrop(32),\n",
    "#     transforms.RandomHorizontalFlip(p=0.5),\n",
    "#     transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "#     transforms.RandomGrayscale(p=0.2),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "#we will aplly 5 different data gmentations (rotations, blur, color distortion, cropping and resizing) for defining the positive samples\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(32),\n",
    "    #random rotation with random angle\n",
    "    transforms.RandomRotation([-1* torch.rand(1)*360 , torch.rand(1)*360]),\n",
    "    #random blur\n",
    "    transforms.RandomApply([transforms.GaussianBlur(3, sigma=[0.1, 2.0])], p=0.5),\n",
    "    #random color distortion\n",
    "    transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "    \n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "\n",
    "# data prepare\n",
    "train_data = CIFAR10Pair(root='data', train=True, transform=train_transform, download=True)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True, drop_last=True)\n",
    "\n",
    "memory_data = CIFAR10(root='data', train=True, transform=test_transform, download=True)\n",
    "memory_loader = DataLoader(memory_data, batch_size=batch_size, shuffle=False, num_workers=16, pin_memory=True)\n",
    "\n",
    "test_data = CIFAR10(root='data', train=False, transform=test_transform, download=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=16, pin_memory=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Batch implementation adapted from: \n",
    "#### https://github.com/davidcpage/cifar10-fast/blob/master/torch_backend.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitBatchNorm(nn.BatchNorm2d):\n",
    "    def __init__(self, num_features, num_splits= bn_splits, **kw):\n",
    "        super().__init__(num_features, **kw)\n",
    "        self.num_splits = num_splits\n",
    "        \n",
    "    def forward(self, input):\n",
    "        N, C, H, W = input.shape\n",
    "        if self.training or not self.track_running_stats:\n",
    "            running_mean_split = self.running_mean.repeat(self.num_splits)\n",
    "            running_var_split = self.running_var.repeat(self.num_splits)\n",
    "            outcome = nn.functional.batch_norm(\n",
    "                input.view(-1, C * self.num_splits, H, W), running_mean_split, running_var_split, \n",
    "                self.weight.repeat(self.num_splits), self.bias.repeat(self.num_splits),\n",
    "                True, self.momentum, self.eps).view(N, C, H, W)\n",
    "            self.running_mean.data.copy_(running_mean_split.view(self.num_splits, C).mean(dim=0))\n",
    "            self.running_var.data.copy_(running_var_split.view(self.num_splits, C).mean(dim=0))\n",
    "            return outcome\n",
    "        else:\n",
    "            return nn.functional.batch_norm(\n",
    "                input, self.running_mean, self.running_var, \n",
    "                self.weight, self.bias, False, self.momentum, self.eps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the following class was adapted from facebookresearch/moco which replaces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #write a function to replace all the batchnorm layers with splitbatchnorm layers if bn_splits > 1\n",
    "# def replace_bn(model, num_splits):\n",
    "#     #if num_splits is 1, then return the model\n",
    "#     if num_splits == 1:\n",
    "#         return model\n",
    "#     norm_layer = partial(SplitBatchNorm, num_splits=bn_splits) if bn_splits > 1 else nn.BatchNorm2d\n",
    "#     for name, child in model.named_children():\n",
    "#         if isinstance(child, nn.BatchNorm2d):\n",
    "#             setattr(model, name, norm_layer(child.num_features))\n",
    "#         else:\n",
    "#             replace_bn(child, num_splits)\n",
    "#     return model\n",
    "    \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to use the class SplitBatchNorm to replace the batchnorm layers with splitbatchnorm layers if bn_splits > 1\n",
    "#the init has num_features and num_splits as arguments, thus while changing the batchnorm layers to splitbatchnorm layers, we need to pass the num_splits as an argument\n",
    "def replace_bn(model, num_splits):\n",
    "    #if num_splits is 1, then return the model\n",
    "    if num_splits == 1:\n",
    "        return model\n",
    "    #loop through the model and replace the batchnorm layers with splitbatchnorm layers using the class SplitBatchNorm\n",
    "    norm_layer = partial(SplitBatchNorm, num_splits=bn_splits)\n",
    "    for name, child in model.named_children():\n",
    "        if isinstance(child, nn.BatchNorm2d):\n",
    "            #change the batchnorm layers to splitbatchnorm layers by the return of the function : SplitBatchNorm(child.num_features, num_splits)\n",
    "            #replace batchnorm with norm_layer\n",
    "            setattr(model, name, norm_layer(child.num_features))\n",
    "        else:\n",
    "            replace_bn(child, num_splits)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class convNet(nn.Module):\n",
    "    def __init__(self, cfg, device):\n",
    "        super(convNet,self).__init__()\n",
    "\n",
    "        self.config = cfg\n",
    "        self.device = device\n",
    "        layers =[]\n",
    "\n",
    "        channel_set=self.config['channels']\n",
    "        for i in range(self.config['num_conv_blocks']):\n",
    "            if i==0:\n",
    "                layers.append(nn.Conv2d(self.config['in_channels'],channel_set[i][1],3, bias=False))\n",
    "            else:\n",
    "                layers.append(nn.Conv2d(channel_set[i][0],channel_set[i][1],3, bias=False))\n",
    "            \n",
    "            layers.append(SplitBatchNorm(channel_set[i][1]))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(p=0.3))\n",
    "            layers.append(nn.AdaptiveMaxPool2d(2))\n",
    "\n",
    "        self.net = nn.ModuleList(layers)\n",
    "        print('-'*59)\n",
    "        print('ConvNet')\n",
    "        print(self.net)\n",
    "        print('-'*59)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        for _, l in enumerate(self.net):\n",
    "            x = l(x)            \n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "ConvNet\n",
      "ModuleList(\n",
      "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (1): SplitBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): Dropout(p=0.3, inplace=False)\n",
      "  (4): AdaptiveMaxPool2d(output_size=2)\n",
      "  (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (6): SplitBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): ReLU()\n",
      "  (8): Dropout(p=0.3, inplace=False)\n",
      "  (9): AdaptiveMaxPool2d(output_size=2)\n",
      "  (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (11): SplitBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (12): ReLU()\n",
      "  (13): Dropout(p=0.3, inplace=False)\n",
      "  (14): AdaptiveMaxPool2d(output_size=2)\n",
      ")\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#create a model\n",
    "\n",
    "test_model = convNet(cfg['model'], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 256, 30, 30]' is invalid for input of size 57600",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/lisa/bhartendu/adrl/A3/MOCO.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#summary of the model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m summary(test_model\u001b[39m.\u001b[39;49mto(device), (\u001b[39m3\u001b[39;49m, \u001b[39m32\u001b[39;49m, \u001b[39m32\u001b[39;49m))\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torchsummary/torchsummary.py:72\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     68\u001b[0m model\u001b[39m.\u001b[39mapply(register_hook)\n\u001b[1;32m     70\u001b[0m \u001b[39m# make a forward pass\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m# print(x.shape)\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m model(\u001b[39m*\u001b[39;49mx)\n\u001b[1;32m     74\u001b[0m \u001b[39m# remove these hooks\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[39mfor\u001b[39;00m h \u001b[39min\u001b[39;00m hooks:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/lisa/bhartendu/adrl/A3/MOCO.ipynb Cell 26\u001b[0m in \u001b[0;36mconvNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,x):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39mfor\u001b[39;00m _, l \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnet):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m         x \u001b[39m=\u001b[39m l(x)            \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1148\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks)\n\u001b[1;32m   1146\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(\u001b[39minput\u001b[39m)\n\u001b[0;32m-> 1148\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1149\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1150\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m (\u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mvalues(), \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n",
      "\u001b[1;32m/home/lisa/bhartendu/adrl/A3/MOCO.ipynb Cell 26\u001b[0m in \u001b[0;36mSplitBatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m running_mean_split \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean\u001b[39m.\u001b[39mrepeat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_splits)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m running_var_split \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var\u001b[39m.\u001b[39mrepeat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_splits)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m outcome \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mbatch_norm(\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, C \u001b[39m*\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_splits, H, W), running_mean_split, running_var_split, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mrepeat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_splits), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias\u001b[39m.\u001b[39mrepeat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_splits),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mTrue\u001b[39;00m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmomentum, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meps)\u001b[39m.\u001b[39mview(N, C, H, W)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mcopy_(running_mean_split\u001b[39m.\u001b[39mview(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_splits, C)\u001b[39m.\u001b[39mmean(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mcopy_(running_var_split\u001b[39m.\u001b[39mview(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_splits, C)\u001b[39m.\u001b[39mmean(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 256, 30, 30]' is invalid for input of size 57600"
     ]
    }
   ],
   "source": [
    "#summary of the model\n",
    "summary(test_model.to(device), (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a class which will define the model: it  will take a base model as input and will replace all the batchnorm layers with splitbatchnorm layers if bn_splits > 1\n",
    "class ModelBase(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super().__init__()\n",
    "        #we get the model from the script models.py named convNet\n",
    "        self.model = convNet( cfg=cfg['model'], device=device)\n",
    "        #we replace the batchnorm layers with splitbatchnorm layers if bn_splits > 1\n",
    "        norm_layer = partial(SplitBatchNorm, num_splits=bn_splits) if bn_splits > 1 else nn.BatchNorm2d\n",
    "        temp_model = getattr(self.model, None)\n",
    "        self.temp_model = temp_model(norm_layer = norm_layer)\n",
    "\n",
    "      \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.temp_model(x)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "ConvNet\n",
      "ModuleList(\n",
      "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): Dropout(p=0.3, inplace=False)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): ReLU()\n",
      "  (8): Dropout(p=0.3, inplace=False)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (12): ReLU()\n",
      "  (13): Dropout(p=0.3, inplace=False)\n",
      "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "-----------------------------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "getattr(): attribute name must be string",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/lisa/bhartendu/adrl/A3/MOCO.ipynb Cell 25\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#create an instance of the class ModelBase\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m ModelBase()\n",
      "\u001b[1;32m/home/lisa/bhartendu/adrl/A3/MOCO.ipynb Cell 25\u001b[0m in \u001b[0;36mModelBase.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m#we replace the batchnorm layers with splitbatchnorm layers if bn_splits > 1\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m norm_layer \u001b[39m=\u001b[39m partial(SplitBatchNorm, num_splits\u001b[39m=\u001b[39mbn_splits) \u001b[39mif\u001b[39;00m bn_splits \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m nn\u001b[39m.\u001b[39mBatchNorm2d\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m temp_model \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtemp_model \u001b[39m=\u001b[39m temp_model(norm_layer \u001b[39m=\u001b[39m norm_layer)\n",
      "\u001b[0;31mTypeError\u001b[0m: getattr(): attribute name must be string"
     ]
    }
   ],
   "source": [
    "#create an instance of the class ModelBase\n",
    "model = ModelBase()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/lisa/bhartendu/adrl/A3/MOCO.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#print summary of the model\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m temp \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m32\u001b[39m, \u001b[39m32\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m summary(model\u001b[39m.\u001b[39;49mto(device), input_size\u001b[39m=\u001b[39;49m(\u001b[39m3\u001b[39;49m, \u001b[39m32\u001b[39;49m, \u001b[39m32\u001b[39;49m), device\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torchsummary/torchsummary.py:72\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     68\u001b[0m model\u001b[39m.\u001b[39mapply(register_hook)\n\u001b[1;32m     70\u001b[0m \u001b[39m# make a forward pass\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m# print(x.shape)\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m model(\u001b[39m*\u001b[39;49mx)\n\u001b[1;32m     74\u001b[0m \u001b[39m# remove these hooks\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[39mfor\u001b[39;00m h \u001b[39min\u001b[39;00m hooks:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/lisa/bhartendu/adrl/A3/MOCO.ipynb Cell 26\u001b[0m in \u001b[0;36mModelBase.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "#print summary of the model\n",
    "temp = torch.randn(1, 3, 32, 32).to(device)\n",
    "summary(model.to(device), input_size=(3, 32, 32), device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "ConvNet\n",
      "ModuleList(\n",
      "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): Dropout(p=0.3, inplace=False)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): ReLU()\n",
      "  (8): Dropout(p=0.3, inplace=False)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (12): ReLU()\n",
      "  (13): Dropout(p=0.3, inplace=False)\n",
      "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#create a calss of convNet to test if it works\n",
    "temp_cnn = convNet( cfg=cfg['model'], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 30, 30]             864\n",
      "       BatchNorm2d-2           [-1, 32, 30, 30]              64\n",
      "              ReLU-3           [-1, 32, 30, 30]               0\n",
      "           Dropout-4           [-1, 32, 30, 30]               0\n",
      "         MaxPool2d-5           [-1, 32, 15, 15]               0\n",
      "            Conv2d-6           [-1, 64, 13, 13]          18,432\n",
      "       BatchNorm2d-7           [-1, 64, 13, 13]             128\n",
      "              ReLU-8           [-1, 64, 13, 13]               0\n",
      "           Dropout-9           [-1, 64, 13, 13]               0\n",
      "        MaxPool2d-10             [-1, 64, 6, 6]               0\n",
      "           Conv2d-11            [-1, 128, 4, 4]          73,728\n",
      "      BatchNorm2d-12            [-1, 128, 4, 4]             256\n",
      "             ReLU-13            [-1, 128, 4, 4]               0\n",
      "          Dropout-14            [-1, 128, 4, 4]               0\n",
      "        MaxPool2d-15            [-1, 128, 2, 2]               0\n",
      "================================================================\n",
      "Total params: 93,472\n",
      "Trainable params: 93,472\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.35\n",
      "Params size (MB): 0.36\n",
      "Estimated Total Size (MB): 1.72\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#print summary of the model\n",
    "temp = torch.randn(1, 3, 32, 32).to(device)\n",
    "summary(temp_cnn.to(device), input_size=(3, 32, 32), device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply replace_bn function to the model\n",
    "temp_cnn = replace_bn(temp_cnn, bn_splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/lisa/bhartendu/adrl/A3/MOCO.ipynb Cell 30\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#summary of the model\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m temp \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m32\u001b[39m, \u001b[39m32\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m summary(temp_cnn\u001b[39m.\u001b[39;49mto(device), input_size\u001b[39m=\u001b[39m(\u001b[39m3\u001b[39m, \u001b[39m32\u001b[39m, \u001b[39m32\u001b[39m), device\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "#summary of the model\n",
    "temp = torch.randn(1, 3, 32, 32).to(device)\n",
    "summary(temp_cnn.to(device), input_size=(3, 32, 32), device='cuda')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelMoCo(nn.Module):\n",
    "    def __init__(self, dim=128, K=4096, m=0.99, T=0.1, arch='resnet18', bn_splits=8, symmetric=True):\n",
    "        super(ModelMoCo, self).__init__()\n",
    "\n",
    "        self.K = K\n",
    "        self.m = m\n",
    "        self.T = T\n",
    "        self.symmetric = symmetric\n",
    "\n",
    "        # create the encoders\n",
    "        self.encoder_q = ModelBase()\n",
    "        self.encoder_k = ModelBase()\n",
    "\n",
    "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
    "            param_k.data.copy_(param_q.data)  # initialize\n",
    "            param_k.requires_grad = False  # not update by gradient\n",
    "\n",
    "        # create the queue\n",
    "        self.register_buffer(\"queue\", torch.randn(dim, K))\n",
    "        self.queue = nn.functional.normalize(self.queue, dim=0)\n",
    "\n",
    "        self.register_buffer(\"queue_ptr\", torch.zeros(1, dtype=torch.long))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _momentum_update_key_encoder(self):\n",
    "        \"\"\"\n",
    "        Momentum update of the key encoder\n",
    "        \"\"\"\n",
    "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
    "            param_k.data = param_k.data * self.m + param_q.data * (1. - self.m)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _dequeue_and_enqueue(self, keys):\n",
    "        batch_size = keys.shape[0]\n",
    "\n",
    "        ptr = int(self.queue_ptr)\n",
    "        assert self.K % batch_size == 0  # for simplicity\n",
    "\n",
    "        # replace the keys at ptr (dequeue and enqueue)\n",
    "        self.queue[:, ptr:ptr + batch_size] = keys.t()  # transpose\n",
    "        ptr = (ptr + batch_size) % self.K  # move pointer\n",
    "\n",
    "        self.queue_ptr[0] = ptr\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _batch_shuffle_single_gpu(self, x):\n",
    "        \"\"\"\n",
    "        Batch shuffle, for making use of BatchNorm.\n",
    "        \"\"\"\n",
    "        # random shuffle index\n",
    "        idx_shuffle = torch.randperm(x.shape[0]).cuda()\n",
    "\n",
    "        # index for restoring\n",
    "        idx_unshuffle = torch.argsort(idx_shuffle)\n",
    "\n",
    "        return x[idx_shuffle], idx_unshuffle\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _batch_unshuffle_single_gpu(self, x, idx_unshuffle):\n",
    "        \"\"\"\n",
    "        Undo batch shuffle.\n",
    "        \"\"\"\n",
    "        return x[idx_unshuffle]\n",
    "\n",
    "    def contrastive_loss(self, im_q, im_k):\n",
    "        # compute query features\n",
    "        q = self.encoder_q(im_q)  # queries: NxC\n",
    "        q = nn.functional.normalize(q, dim=1)  # already normalized\n",
    "\n",
    "        # compute key features\n",
    "        with torch.no_grad():  # no gradient to keys\n",
    "            # shuffle for making use of BN\n",
    "            im_k_, idx_unshuffle = self._batch_shuffle_single_gpu(im_k)\n",
    "\n",
    "            k = self.encoder_k(im_k_)  # keys: NxC\n",
    "            k = nn.functional.normalize(k, dim=1)  # already normalized\n",
    "\n",
    "            # undo shuffle\n",
    "            k = self._batch_unshuffle_single_gpu(k, idx_unshuffle)\n",
    "\n",
    "        # compute logits\n",
    "        # Einstein sum is more intuitive\n",
    "        # positive logits: Nx1\n",
    "        l_pos = torch.einsum('nc,nc->n', [q, k]).unsqueeze(-1)\n",
    "        # negative logits: NxK\n",
    "        l_neg = torch.einsum('nc,ck->nk', [q, self.queue.clone().detach()])\n",
    "\n",
    "        # logits: Nx(1+K)\n",
    "        logits = torch.cat([l_pos, l_neg], dim=1)\n",
    "\n",
    "        # apply temperature\n",
    "        logits /= self.T\n",
    "\n",
    "        # labels: positive key indicators\n",
    "        labels = torch.zeros(logits.shape[0], dtype=torch.long).cuda()\n",
    "        \n",
    "        loss = nn.CrossEntropyLoss().cuda()(logits, labels)\n",
    "\n",
    "        return loss, q, k\n",
    "\n",
    "    def forward(self, im1, im2):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            im_q: a batch of query images\n",
    "            im_k: a batch of key images\n",
    "        Output:\n",
    "            loss\n",
    "        \"\"\"\n",
    "\n",
    "        # update the key encoder\n",
    "        with torch.no_grad():  # no gradient to keys\n",
    "            self._momentum_update_key_encoder()\n",
    "\n",
    "        # compute loss\n",
    "        if self.symmetric:  # asymmetric loss\n",
    "            loss_12, q1, k2 = self.contrastive_loss(im1, im2)\n",
    "            loss_21, q2, k1 = self.contrastive_loss(im2, im1)\n",
    "            loss = loss_12 + loss_21\n",
    "            k = torch.cat([k1, k2], dim=0)\n",
    "        else:  # asymmetric loss\n",
    "            loss, q, k = self.contrastive_loss(im1, im2)\n",
    "\n",
    "        self._dequeue_and_enqueue(k)\n",
    "\n",
    "        return loss\n",
    "\n",
    "# create model\n",
    "model = ModelMoCo(\n",
    "        dim=args.moco_dim,\n",
    "        K=args.moco_k,\n",
    "        m=args.moco_m,\n",
    "        T=args.moco_t,\n",
    "        arch=args.arch,\n",
    "        bn_splits=args.bn_splits,\n",
    "        symmetric=args.symmetric,\n",
    "    ).cuda()\n",
    "print(model.encoder_q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "079402cc50f681fca3bc4b588c8594ae5b0127c6215ec7c89d21fdfb87f97274"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
