{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in this notebook we will implement MOCO paper:\n",
    "#https://arxiv.org/pdf/1911.05722.pdf\n",
    "#CNN architecture we change, but MOCO loss function is the same, and training is the same\n",
    "#we use 5 different data gmentations (rotations, blur, color distortion, cropping and resizing) for defining the positive samples\n",
    "\n",
    "#training is done on 1 GPU, training setting are:\n",
    "#1. Use the entire training data to learn the representations.\n",
    "#2. Once the representations are learned, use a linear and logistic layers and retrain with 10-50% of supervised training data.\n",
    "#3. Experiment with two different sizes for the encoder dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 7\n",
    "experiment = 'moco_split_norm'\n",
    "experiment_name = experiment + '_' + str(version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "\n",
    "from functools import partial\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "#tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'config' from '/home/lisa/bhartendu/adrl/A3/config.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "import models\n",
    "importlib.reload(models)\n",
    "from models import  pentaClassifier, binaryClassifier, baseClassifier, convNet\n",
    "\n",
    "\n",
    "import config\n",
    "from config import cfg\n",
    "importlib.reload(config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed\n",
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "# Torch RNG\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HYPER - PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = 'results/'\n",
    "moco_pretrained_dir = results_dir+'model_'+experiment_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MOCO - HYPER - PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "moco_dim = 512\n",
    "moco_k = 4096\n",
    "moco_m = 0.99\n",
    "moco_t = 0.07\n",
    "moco_loss_symmetric = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MOCO - TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.06\n",
    "epochs = 200  # 200\n",
    "batch_size = 512\n",
    "schedule = [120, 160]\n",
    "wd = 5e-4\n",
    "cos = True      # cosine lr schedule\n",
    "bn_splits = 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supervised - Hyper - Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_training_data = 0.50"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supervised Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_lr = 5.0\n",
    "super_epochs = 10\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data-loader\n",
    "\n",
    "#### Adapted from pytorch code of Contrastive learning libs: http://github.com/zhirongw/lemniscate.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "class CIFAR10Pair(CIFAR10):\n",
    "    \"\"\"CIFAR10 Dataset.\n",
    "    \"\"\"\n",
    "    def __getitem__(self, index):\n",
    "        img = self.data[index]\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            im_1 = self.transform(img)\n",
    "            im_2 = self.transform(img)\n",
    "\n",
    "        return im_1, im_2\n",
    "\n",
    "# train_transform = transforms.Compose([\n",
    "#     transforms.RandomResizedCrop(32),\n",
    "#     transforms.RandomHorizontalFlip(p=0.5),\n",
    "#     transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "#     transforms.RandomGrayscale(p=0.2),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "#we will aplly 5 different data gmentations (rotations, blur, color distortion, cropping and resizing) for defining the positive samples\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(32),\n",
    "    #random rotation with random angle\n",
    "    transforms.RandomRotation([-1* torch.rand(1)*360 , torch.rand(1)*360]),\n",
    "    #random blur\n",
    "    transforms.RandomApply([transforms.GaussianBlur(3, sigma=[0.1, 2.0])], p=0.5),\n",
    "    #random color distortion\n",
    "    transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "    \n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "\n",
    "# data prepare\n",
    "train_data = CIFAR10Pair(root='data', train=True, transform=train_transform, download=True)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True, drop_last=True)\n",
    "\n",
    "memory_data = CIFAR10(root='data', train=True, transform=test_transform, download=True)\n",
    "memory_loader = DataLoader(memory_data, batch_size=batch_size, shuffle=False, num_workers=16, pin_memory=True)\n",
    "\n",
    "test_data = CIFAR10(root='data', train=False, transform=test_transform, download=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=16, pin_memory=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Batch implementation adapted from: \n",
    "#### https://timm.fast.ai/tutorial_splitbn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitBatchNorm2d(torch.nn.BatchNorm2d):\n",
    "\n",
    "    def __init__(self, num_features, eps=1e-5, momentum=0.1, affine=True,\n",
    "                 track_running_stats=True, num_splits=2):\n",
    "        super().__init__(num_features, eps, momentum, affine, track_running_stats)\n",
    "        assert num_splits > 1, 'Should have at least one aux BN layer (num_splits at least 2)'\n",
    "        self.num_splits = num_splits\n",
    "        self.aux_bn = nn.ModuleList([\n",
    "            nn.BatchNorm2d(num_features, eps, momentum, affine, track_running_stats) for _ in range(num_splits - 1)])\n",
    "\n",
    "    def forward(self, input: torch.Tensor):\n",
    "        if self.training:  # aux BN only relevant while training\n",
    "            split_size = input.shape[0] // self.num_splits\n",
    "            assert input.shape[0] == split_size * self.num_splits, \"batch size must be evenly divisible by num_splits\"\n",
    "            split_input = input.split(split_size)\n",
    "            x = [super().forward(split_input[0])]\n",
    "            for i, a in enumerate(self.aux_bn):\n",
    "                x.append(a(split_input[i + 1]))\n",
    "            return torch.cat(x, dim=0)\n",
    "        else:\n",
    "            return super().forward(input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### functionality to replace BatchNorm with SplitBatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a function to replace batchnorm with splitbatchnorm\n",
    "def internal_replace_batch_norm_w_split_norm(model, num_splits = 2):\n",
    "    #if num_splits is 1, then we will not replace the batchnorm with splitbatchnorm, return the model as it is\n",
    "    if num_splits == 1:\n",
    "        return model\n",
    "    out = False\n",
    "\n",
    "    for parent_module in model.modules():\n",
    "        #iterate over all the children of the parent module\n",
    "        for child_module in parent_module.children():\n",
    "            #if the child module is batchnorm, then replace it with splitbatchnorm\n",
    "            if isinstance(child_module, torch.nn.BatchNorm2d):\n",
    "                #first make copy of all the parameters of the batchnorm\n",
    "                num_features = child_module.num_features\n",
    "                eps = child_module.eps\n",
    "                momentum = child_module.momentum\n",
    "                affine = child_module.affine\n",
    "                track_running_stats = child_module.track_running_stats\n",
    "                #now replace the batchnorm with splitbatchnorm\n",
    "                parent_module._modules[str(child_module)] = SplitBatchNorm2d(num_features, eps, momentum, affine, track_running_stats, num_splits)\n",
    "                out = True\n",
    "                # if out is true break the loop\n",
    "                if out:\n",
    "                    break\n",
    "                \n",
    "        # break if out is true\n",
    "        if out:\n",
    "            break\n",
    "    return model, out\n",
    "    \n",
    "\n",
    "#function to count the number of batchnorm layers in the model\n",
    "def count_bn_layers(model):\n",
    "    count = 0\n",
    "    for parent_module in model.modules():\n",
    "        for child_module in parent_module.children():\n",
    "            if isinstance(child_module, torch.nn.BatchNorm2d):\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "#write a function to replace splitbatchnorm with batchnorm by using both functions defined above\n",
    "def batch_norm_w_split_norm(model , num_splits= 2, verbose = False):\n",
    "    #if num_splits is 1, then we will not replace the batchnorm with splitbatchnorm, return the model as it is\n",
    "    if num_splits == 1:\n",
    "        return model\n",
    "    #first get the number of batchnorm layers in the model\n",
    "    num_bn_layers = count_bn_layers(model)\n",
    "    #if the number of batchnorm layers is 0, then return the model as it is\n",
    "    if num_bn_layers == 0:\n",
    "        return model\n",
    "    #if verbose then print the number of batchnorm layers\n",
    "    if verbose:\n",
    "        print(\"Number of batchnorm layers in the model: \", num_bn_layers)\n",
    "\n",
    "    #if the number of batchnorm layers is not 0, then replace the batchnorm with splitbatchnorm using the function replace_batch_norm_w_split_norm : internal_replace_batch_norm_w_split_norm\n",
    "    for i in range(num_bn_layers):\n",
    "        model, out = internal_replace_batch_norm_w_split_norm(model, num_splits)\n",
    "        #if verbose then print the number of batchnorm layers replaced\n",
    "        if verbose:\n",
    "            print(\"Number of batchnorm layers replaced: \", i+1)\n",
    "        assert out, \"Error in replacing batchnorm with splitbatchnorm\"\n",
    "    return model\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a model class named ModelBAse that will have the exact same architecture as the convNet class but will flatten the output of the model, to get embedding of the model\n",
    "class ModelBase(nn.Module):\n",
    "    def __init__(self, cfg=cfg['model'], device=device):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.device = device\n",
    "        self.conv= batch_norm_w_split_norm(convNet(cfg, device=device), num_splits=bn_splits)\n",
    "        self.flat = nn.Flatten()\n",
    "        self.fc = nn.Linear(moco_dim, moco_dim)\n",
    "        #replace the batchnorm with splitbatchnorm\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flat(self.conv(x))\n",
    "        #pass the output of the model through a linear layer\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "ConvNet\n",
      "ModuleList(\n",
      "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): Dropout(p=0.3, inplace=False)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): ReLU()\n",
      "  (8): Dropout(p=0.3, inplace=False)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (12): ReLU()\n",
      "  (13): Dropout(p=0.3, inplace=False)\n",
      "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#buils an object of the ModelBase class\n",
    "model = ModelBase()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelBase(\n",
      "  (conv): convNet(\n",
      "    (net): ModuleList(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Dropout(p=0.3, inplace=False)\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (7): ReLU()\n",
      "      (8): Dropout(p=0.3, inplace=False)\n",
      "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (12): ReLU()\n",
      "      (13): Dropout(p=0.3, inplace=False)\n",
      "      (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)): SplitBatchNorm2d(\n",
      "        32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (aux_bn): ModuleList(\n",
      "          (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#print the model\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #summary of the model\n",
    "# #create a dummy input\n",
    "# dummy_input = torch.randn( 3, 32, 32)\n",
    "\n",
    "\n",
    "# summary(model, input_size=(8,3, 32, 32), device='cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------\n",
    "---------------------------------------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOCO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### defininng MOCO Training Routine: Including the queue and the memory bank and key encoder, query encoder\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the following class was adapted from facebookresearch/moco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelMoCo(nn.Module):\n",
    "    def __init__(self, dim=moco_dim, K=moco_k, m=moco_m, T=moco_t, bn_splits=bn_splits, symmetric=True):\n",
    "        super(ModelMoCo, self).__init__()\n",
    "\n",
    "        self.K = K\n",
    "        self.m = m\n",
    "        self.T = T\n",
    "        self.symmetric = symmetric\n",
    "\n",
    "        # create the encoders\n",
    "        self.encoder_q = ModelBase()\n",
    "        self.encoder_k = ModelBase()\n",
    "\n",
    "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
    "            param_k.data.copy_(param_q.data)  # initialize\n",
    "            param_k.requires_grad = False  # not update by gradient\n",
    "\n",
    "        # create the queue\n",
    "        self.register_buffer(\"queue\", torch.randn(dim, K))\n",
    "        self.queue = nn.functional.normalize(self.queue, dim=0)\n",
    "\n",
    "        self.register_buffer(\"queue_ptr\", torch.zeros(1, dtype=torch.long))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _momentum_update_key_encoder(self):\n",
    "        \"\"\"\n",
    "        Momentum update of the key encoder\n",
    "        \"\"\"\n",
    "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
    "            param_k.data = param_k.data * self.m + param_q.data * (1. - self.m)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _dequeue_and_enqueue(self, keys):\n",
    "        batch_size = keys.shape[0]\n",
    "\n",
    "        ptr = int(self.queue_ptr)\n",
    "        assert self.K % batch_size == 0  # for simplicity\n",
    "\n",
    "        # replace the keys at ptr (dequeue and enqueue)\n",
    "        self.queue[:, ptr:ptr + batch_size] = keys.t()  # transpose\n",
    "        ptr = (ptr + batch_size) % self.K  # move pointer\n",
    "\n",
    "        self.queue_ptr[0] = ptr\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _batch_shuffle_single_gpu(self, x):\n",
    "        \"\"\"\n",
    "        Batch shuffle, for making use of BatchNorm.\n",
    "        \"\"\"\n",
    "        # random shuffle index\n",
    "        idx_shuffle = torch.randperm(x.shape[0]).cuda()\n",
    "\n",
    "        # index for restoring\n",
    "        idx_unshuffle = torch.argsort(idx_shuffle)\n",
    "\n",
    "        return x[idx_shuffle], idx_unshuffle\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _batch_unshuffle_single_gpu(self, x, idx_unshuffle):\n",
    "        \"\"\"\n",
    "        Undo batch shuffle.\n",
    "        \"\"\"\n",
    "        return x[idx_unshuffle]\n",
    "\n",
    "    def contrastive_loss(self, im_q, im_k):\n",
    "        # compute query features\n",
    "        q = self.encoder_q(im_q)  # queries: NxC\n",
    "        q = nn.functional.normalize(q, dim=1)  # already normalized\n",
    "\n",
    "        # compute key features\n",
    "        with torch.no_grad():  # no gradient to keys\n",
    "            # shuffle for making use of BN\n",
    "            im_k_, idx_unshuffle = self._batch_shuffle_single_gpu(im_k)\n",
    "\n",
    "            k = self.encoder_k(im_k_)  # keys: NxC\n",
    "            k = nn.functional.normalize(k, dim=1)  # already normalized\n",
    "\n",
    "            # undo shuffle\n",
    "            k = self._batch_unshuffle_single_gpu(k, idx_unshuffle)\n",
    "\n",
    "        # compute logits\n",
    "        # Einstein sum is more intuitive\n",
    "        # positive logits: Nx1\n",
    "        l_pos = torch.einsum('nc,nc->n', [q, k]).unsqueeze(-1)\n",
    "        # negative logits: NxK\n",
    "        l_neg = torch.einsum('nc,ck->nk', [q, self.queue.clone().detach()])\n",
    "\n",
    "        # logits: Nx(1+K)\n",
    "        logits = torch.cat([l_pos, l_neg], dim=1)\n",
    "\n",
    "        # apply temperature\n",
    "        logits /= self.T\n",
    "\n",
    "        # labels: positive key indicators\n",
    "        labels = torch.zeros(logits.shape[0], dtype=torch.long).cuda()\n",
    "        \n",
    "        loss = nn.CrossEntropyLoss().cuda()(logits, labels)\n",
    "\n",
    "        return loss, q, k\n",
    "\n",
    "    def forward(self, im1, im2):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            im_q: a batch of query images\n",
    "            im_k: a batch of key images\n",
    "        Output:\n",
    "            loss\n",
    "        \"\"\"\n",
    "\n",
    "        # update the key encoder\n",
    "        with torch.no_grad():  # no gradient to keys\n",
    "            self._momentum_update_key_encoder()\n",
    "\n",
    "        # compute loss\n",
    "        if self.symmetric:  # asymmetric loss\n",
    "            loss_12, q1, k2 = self.contrastive_loss(im1, im2)\n",
    "            loss_21, q2, k1 = self.contrastive_loss(im2, im1)\n",
    "            loss = loss_12 + loss_21\n",
    "            k = torch.cat([k1, k2], dim=0)\n",
    "        else:  # asymmetric loss\n",
    "            loss, q, k = self.contrastive_loss(im1, im2)\n",
    "\n",
    "        self._dequeue_and_enqueue(k)\n",
    "\n",
    "        return loss\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer: SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### learning rate schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr scheduler for training\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Decay the learning rate based on schedule\"\"\"\n",
    "    learning_rate = lr \n",
    "    if cos:  # cosine lr schedule\n",
    "        learning_rate *= 0.5 * (1. + math.cos(math.pi * epoch / epochs))\n",
    "    else:  # stepwise lr schedule\n",
    "        for milestone in schedule:\n",
    "            learning_rate *= 0.1 if epoch >= milestone else 1.\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = learning_rate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 10:00:50.563170: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "# train for one epoch\n",
    "#create batch writer\n",
    "batch_writer = SummaryWriter(f'{results_dir}/run/')\n",
    "batch_count = 0\n",
    "\n",
    "\n",
    "def train(net, data_loader, train_optimizer, epoch):\n",
    "    net.train()\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    total_loss, total_num, train_bar = 0.0, 0, tqdm(data_loader)\n",
    "    for im_1, im_2 in train_bar:\n",
    "        im_1, im_2 = im_1.cuda(non_blocking=True), im_2.cuda(non_blocking=True)\n",
    "\n",
    "        loss = net(im_1, im_2)\n",
    "        \n",
    "        train_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        train_optimizer.step()\n",
    "\n",
    "        #write to batch writer\n",
    "        #make batch count static\n",
    "        global batch_count\n",
    "        batch_writer.add_scalar('Loss/train_batch', loss, batch_count)\n",
    "        batch_count += 1\n",
    "        ########\n",
    "\n",
    "        total_num += data_loader.batch_size\n",
    "        total_loss += loss.item() * data_loader.batch_size\n",
    "        train_bar.set_description('Train Epoch: [{}/{}], lr: {:.6f}, Loss: {:.4f}'.format(epoch, epochs, optimizer.param_groups[0]['lr'], total_loss / total_num))\n",
    "\n",
    "    return total_loss / total_num\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "ConvNet\n",
      "ModuleList(\n",
      "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): Dropout(p=0.3, inplace=False)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): ReLU()\n",
      "  (8): Dropout(p=0.3, inplace=False)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (12): ReLU()\n",
      "  (13): Dropout(p=0.3, inplace=False)\n",
      "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "ConvNet\n",
      "ModuleList(\n",
      "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): Dropout(p=0.3, inplace=False)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): ReLU()\n",
      "  (8): Dropout(p=0.3, inplace=False)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (12): ReLU()\n",
      "  (13): Dropout(p=0.3, inplace=False)\n",
      "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "-----------------------------------------------------------\n",
      "ModelBase(\n",
      "  (conv): convNet(\n",
      "    (net): ModuleList(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Dropout(p=0.3, inplace=False)\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (7): ReLU()\n",
      "      (8): Dropout(p=0.3, inplace=False)\n",
      "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (12): ReLU()\n",
      "      (13): Dropout(p=0.3, inplace=False)\n",
      "      (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)): SplitBatchNorm2d(\n",
      "        32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (aux_bn): ModuleList(\n",
      "          (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = ModelMoCo(\n",
    "        dim=moco_dim,\n",
    "        K=moco_k,\n",
    "        m=moco_m,\n",
    "        T=moco_t,\n",
    "\n",
    "        bn_splits=bn_splits,\n",
    "        symmetric=moco_loss_symmetric,\n",
    "    ).to(device)\n",
    "print(model.encoder_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging\n",
    "results = {'train_loss': []}\n",
    "#if results_dir not exists, then create one\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "#initialize summary writer in run directory in results_dir\n",
    "writer = SummaryWriter(f'{results_dir}/run/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/97 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "running_mean should contain 128 elements not 32",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/lisa/bhartendu/adrl/A3/MOCO_2_model_split_norm.ipynb Cell 48\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO_2_model_split_norm.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m epoch_start \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO_2_model_split_norm.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epoch_start, epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO_2_model_split_norm.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     train_loss \u001b[39m=\u001b[39m train(model, train_loader, optimizer, epoch)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO_2_model_split_norm.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     results[\u001b[39m'\u001b[39m\u001b[39mtrain_loss\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(train_loss)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO_2_model_split_norm.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     writer\u001b[39m.\u001b[39madd_scalar(\u001b[39m'\u001b[39m\u001b[39mLoss/train_epoch\u001b[39m\u001b[39m'\u001b[39m, train_loss, epoch)\n",
      "\u001b[1;32m/home/lisa/bhartendu/adrl/A3/MOCO_2_model_split_norm.ipynb Cell 48\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, data_loader, train_optimizer, epoch)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO_2_model_split_norm.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfor\u001b[39;00m im_1, im_2 \u001b[39min\u001b[39;00m train_bar:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO_2_model_split_norm.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     im_1, im_2 \u001b[39m=\u001b[39m im_1\u001b[39m.\u001b[39mcuda(non_blocking\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), im_2\u001b[39m.\u001b[39mcuda(non_blocking\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO_2_model_split_norm.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     loss \u001b[39m=\u001b[39m net(im_1, im_2)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO_2_model_split_norm.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     train_optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO_2_model_split_norm.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/lisa/bhartendu/adrl/A3/MOCO_2_model_split_norm.ipynb Cell 48\u001b[0m in \u001b[0;36mModelMoCo.forward\u001b[0;34m(self, im1, im2)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO_2_model_split_norm.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=113'>114</a>\u001b[0m \u001b[39m# compute loss\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO_2_model_split_norm.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=114'>115</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msymmetric:  \u001b[39m# asymmetric loss\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO_2_model_split_norm.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=115'>116</a>\u001b[0m     loss_12, q1, k2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcontrastive_loss(im1, im2)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO_2_model_split_norm.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=116'>117</a>\u001b[0m     loss_21, q2, k1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrastive_loss(im2, im1)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO_2_model_split_norm.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=117'>118</a>\u001b[0m     loss \u001b[39m=\u001b[39m loss_12 \u001b[39m+\u001b[39m loss_21\n",
      "\u001b[1;32m/home/lisa/bhartendu/adrl/A3/MOCO_2_model_split_norm.ipynb Cell 48\u001b[0m in \u001b[0;36mModelMoCo.contrastive_loss\u001b[0;34m(self, im_q, im_k)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO_2_model_split_norm.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcontrastive_loss\u001b[39m(\u001b[39mself\u001b[39m, im_q, im_k):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO_2_model_split_norm.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m     \u001b[39m# compute query features\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO_2_model_split_norm.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=66'>67</a>\u001b[0m     q \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder_q(im_q)  \u001b[39m# queries: NxC\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO_2_model_split_norm.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=67'>68</a>\u001b[0m     q \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mnormalize(q, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)  \u001b[39m# already normalized\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO_2_model_split_norm.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=69'>70</a>\u001b[0m     \u001b[39m# compute key features\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/lisa/bhartendu/adrl/A3/MOCO_2_model_split_norm.ipynb Cell 48\u001b[0m in \u001b[0;36mModelBase.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO_2_model_split_norm.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO_2_model_split_norm.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflat(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv(x))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO_2_model_split_norm.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m#pass the output of the model through a linear layer\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO_2_model_split_norm.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/bhartendu/adrl/A3/models.py:34\u001b[0m, in \u001b[0;36mconvNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,x):\n\u001b[1;32m     33\u001b[0m     \u001b[39mfor\u001b[39;00m _, l \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnet):\n\u001b[0;32m---> 34\u001b[0m         x \u001b[39m=\u001b[39m l(x)            \n\u001b[1;32m     36\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/lisa/bhartendu/adrl/A3/MOCO_2_model_split_norm.ipynb Cell 48\u001b[0m in \u001b[0;36mSplitBatchNorm2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO_2_model_split_norm.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m split_size \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_splits, \u001b[39m\"\u001b[39m\u001b[39mbatch size must be evenly divisible by num_splits\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO_2_model_split_norm.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m split_input \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msplit(split_size)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO_2_model_split_norm.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m x \u001b[39m=\u001b[39m [\u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mforward(split_input[\u001b[39m0\u001b[39;49m])]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO_2_model_split_norm.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, a \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maux_bn):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A3/MOCO_2_model_split_norm.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     x\u001b[39m.\u001b[39mappend(a(split_input[i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m]))\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m     bn_training \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    163\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[39mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[39mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m    169\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    170\u001b[0m     \u001b[39m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    171\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean\n\u001b[1;32m    172\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats\n\u001b[1;32m    173\u001b[0m     \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    174\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    175\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    176\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    177\u001b[0m     bn_training,\n\u001b[1;32m    178\u001b[0m     exponential_average_factor,\n\u001b[1;32m    179\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[1;32m    180\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2438\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2435\u001b[0m \u001b[39mif\u001b[39;00m training:\n\u001b[1;32m   2436\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[0;32m-> 2438\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m   2439\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled\n\u001b[1;32m   2440\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: running_mean should contain 128 elements not 32"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "epoch_start = 1\n",
    "for epoch in range(epoch_start, epochs + 1):\n",
    "    \n",
    "    train_loss = train(model, train_loader, optimizer, epoch)\n",
    "    results['train_loss'].append(train_loss)\n",
    "    writer.add_scalar('Loss/train_epoch', train_loss, epoch)\n",
    "    #if last epoch save model\n",
    "    if epoch == epochs:\n",
    "        torch.save(model.state_dict(), moco_pretrained_dir+'.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #write a function to load the trained moco model, \n",
    "# def load_moco_model(path = moco_pretrained_dir):\n",
    "#     model = ModelMoCo(\n",
    "#         dim=moco_dim,\n",
    "#         K=moco_k,\n",
    "#         m=moco_m,\n",
    "#         T=moco_t,\n",
    "\n",
    "#         bn_splits=bn_splits,\n",
    "#         symmetric=moco_loss_symmetric,\n",
    "#     )\n",
    "#     model.load_state_dict(torch.load(path))\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load saved moco model but return only the encoder_q\n",
    "def load_moco_model(path = moco_pretrained_dir):\n",
    "    model = ModelMoCo(\n",
    "        dim=moco_dim,\n",
    "        K=moco_k,\n",
    "        m=moco_m,\n",
    "        T=moco_t,\n",
    "\n",
    "        bn_splits=bn_splits,\n",
    "        symmetric=moco_loss_symmetric,\n",
    "    )\n",
    "    model.load_state_dict(torch.load(path+'.pth'))\n",
    "    return model.encoder_q\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Learned Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will test using the standard Linear classification Protocol\n",
    "#the Linear classification Protocol is : as unsupervised representations are learned, use a linear and logistic layers and retrain with 10-50% of supervised training data\n",
    "\n",
    "#we have 2 test tasks \n",
    "#TASK 1: Binary Classifier\n",
    "#TASk 2: 5-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we define a classifier class, that takes in number of classes\n",
    "#it will first make a copy of the ModelMoCo class, load the pretrained weights, make the weights non-trainable\n",
    "#then we will add a linear layer and a logistic layer to the model to match the number of classes\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.moco = load_moco_model()\n",
    "        #freeze the weights\n",
    "        for param in self.moco.parameters():\n",
    "            param.requires_grad = False\n",
    "        #add a linear layer and a softmax layer\n",
    "        self.linear = nn.Linear(moco_dim, num_classes)\n",
    "        #add logistic layer\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        x = self.moco(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "ConvNet\n",
      "ModuleList(\n",
      "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): Dropout(p=0.3, inplace=False)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): ReLU()\n",
      "  (8): Dropout(p=0.3, inplace=False)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (12): ReLU()\n",
      "  (13): Dropout(p=0.3, inplace=False)\n",
      "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "ConvNet\n",
      "ModuleList(\n",
      "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): Dropout(p=0.3, inplace=False)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): ReLU()\n",
      "  (8): Dropout(p=0.3, inplace=False)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (12): ReLU()\n",
      "  (13): Dropout(p=0.3, inplace=False)\n",
      "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "-----------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 30, 30]             864\n",
      "       BatchNorm2d-2           [-1, 32, 30, 30]              64\n",
      "              ReLU-3           [-1, 32, 30, 30]               0\n",
      "           Dropout-4           [-1, 32, 30, 30]               0\n",
      "         MaxPool2d-5           [-1, 32, 15, 15]               0\n",
      "            Conv2d-6           [-1, 64, 13, 13]          18,432\n",
      "       BatchNorm2d-7           [-1, 64, 13, 13]             128\n",
      "              ReLU-8           [-1, 64, 13, 13]               0\n",
      "           Dropout-9           [-1, 64, 13, 13]               0\n",
      "        MaxPool2d-10             [-1, 64, 6, 6]               0\n",
      "           Conv2d-11            [-1, 128, 4, 4]          73,728\n",
      "      BatchNorm2d-12            [-1, 128, 4, 4]             256\n",
      "             ReLU-13            [-1, 128, 4, 4]               0\n",
      "          Dropout-14            [-1, 128, 4, 4]               0\n",
      "        MaxPool2d-15            [-1, 128, 2, 2]               0\n",
      "          convNet-16            [-1, 128, 2, 2]               0\n",
      "          Flatten-17                  [-1, 512]               0\n",
      "           Linear-18                  [-1, 512]         262,656\n",
      "        ModelBase-19                  [-1, 512]               0\n",
      "           Linear-20                    [-1, 2]           1,026\n",
      "          Softmax-21                    [-1, 2]               0\n",
      "================================================================\n",
      "Total params: 357,154\n",
      "Trainable params: 1,026\n",
      "Non-trainable params: 356,128\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.36\n",
      "Params size (MB): 1.36\n",
      "Estimated Total Size (MB): 2.74\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#print summary of the model\n",
    "model = Classifier(2)\n",
    "summary(model.to(device), (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier(\n",
      "  (moco): ModelBase(\n",
      "    (conv): convNet(\n",
      "      (net): ModuleList(\n",
      "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.3, inplace=False)\n",
      "        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU()\n",
      "        (8): Dropout(p=0.3, inplace=False)\n",
      "        (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (12): ReLU()\n",
      "        (13): Dropout(p=0.3, inplace=False)\n",
      "        (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "    (flat): Flatten(start_dim=1, end_dim=-1)\n",
      "    (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "  )\n",
      "  (linear): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dataloader for supervised training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#define train and test loaders\n",
    "#get train loader only fraction_trainig_data\n",
    "#we load cifar10 dataset from torchvision\n",
    "train_data_supervised = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=test_transform)\n",
    "#take only fraction of training data : fraction_training_data \n",
    "train_data_supervised = torch.utils.data.Subset(train_data_supervised, indices = np.random.choice(len(train_data_supervised), int(fraction_training_data*len(train_data_supervised)), replace=False))\n",
    "\n",
    "#train dataloader\n",
    "train_loader_supervised = torch.utils.data.DataLoader(train_data_supervised, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supervised Training Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will have a supervised training loop on a model given by the classifier class\n",
    "def supervised_training(model,label_fun, model_save_path, epochs= super_epochs, lr):\n",
    "\n",
    "    #loss function\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    #optimizer, we will only train the linear and logistic layers, thus we will only pass the parameters of the linear and logistic layers, i.e only the trainable parameters\n",
    "    #pass only the parameters of last linear layer and softmax layer\n",
    "    optimizer = torch.optim.SGD(model.linear.parameters(), lr=super_lr)\n",
    "    #CosineAnnealingLR scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "\n",
    "\n",
    "\n",
    "    model.train()\n",
    "    #send model to device\n",
    "    model.to(device)\n",
    "    train_bar = tqdm(train_loader)\n",
    "    #loop for number of epochs\n",
    "    batch_counter = 0\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        total_correct = 0\n",
    "        total_items = 0\n",
    "        #loop for number of batches\n",
    "        for batch_idx, (data, target) in enumerate(train_loader_supervised):\n",
    "            #send data and target to device\n",
    "            data, target = data.to(device), target\n",
    "            #get binary target\n",
    "            target = label_fun(target)\n",
    "            #send to device\n",
    "            target = target.to(device)\n",
    "            #zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            #forward pass\n",
    "            output = model(data)\n",
    "            #calculate loss\n",
    "            loss = criterion(output, target)\n",
    "            #backward pass\n",
    "            loss.backward()\n",
    "            #update weights\n",
    "            optimizer.step()\n",
    "            #update epoch loss\n",
    "            epoch_loss += loss.item()\n",
    "            #get classification accuracy\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total = target.size(0)\n",
    "            correct = (predicted == target).sum().item()\n",
    "            total_correct += correct\n",
    "            total_items += total\n",
    "            #update progress bar\n",
    "            # train_bar.set_description(desc= f'epoch {epoch} loss={loss.item()} batch_id={batch_idx} Accuracy={100 * correct / total}')\n",
    "            #print\n",
    "            if batch_idx % 25 == 0:\n",
    "                print('Epoch : %d/%d, Batch : %d/%d, Loss : %.4f, Accuracy : %.4f'\n",
    "                    %(epoch+1, epochs, batch_idx+1, len(train_loader_supervised), loss.item(), 100 * correct / total))\n",
    "\n",
    "            #write to tensorboard\n",
    "            writer.add_scalar('Loss/batch_train_supervised_binary_classifier', loss.item(), batch_counter)\n",
    "            writer.add_scalar('Accuracy/batch_train_supervised_binary_classifier', 100 * correct / total, batch_counter)\n",
    "            batch_counter += 1\n",
    "\n",
    "        #update scheduler\n",
    "        scheduler.step()\n",
    "        #print epoch loss\n",
    "        print(\"epoch loss\",epoch_loss/len(train_loader))\n",
    "        #print epoch accuracy\n",
    "        print(\"epoch accuracy\",total_correct/total_items)\n",
    "        #write to tensorboard\n",
    "        writer.add_scalar('Loss/epoch_train_supervised_binary_classifier', epoch_loss/len(train_loader), epoch)\n",
    "        writer.add_scalar('Accuracy/epoch_train_supervised_binary_classifier', total_correct/total_items, epoch)\n",
    "        #if last epoch , then save the model\n",
    "        if epoch == epochs-1:\n",
    "            torch.save(model.state_dict(), model_save_path+'.pt')\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## TASK 0: CIFAR10 10-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define 10 class label\n",
    "def ten_class_label(ip):\n",
    "    return ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will call the supervised training function for 10 class classification\n",
    "#we will build the parameters for the function\n",
    "#model\n",
    "model = Classifier(10)\n",
    "model_save_path = moco_pretrained_dir + '_supervised_ten_class_classifier'\n",
    "#call the function\n",
    "model = supervised_training(model, ten_class_label, model_save_path, epochs= super_epochs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## TASK 1: Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will define binary label function that will map the input label: 0 to 9 to either 0 or 1\n",
    "#y = torch.tensor([1 if x in [2,3,4,5,6,7] else 0 for x in y])\n",
    "def binary_label(y):\n",
    "    y = torch.tensor([1 if x in [2,3,4,5,6,7] else 0 for x in y])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "ConvNet\n",
      "ModuleList(\n",
      "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): Dropout(p=0.3, inplace=False)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): ReLU()\n",
      "  (8): Dropout(p=0.3, inplace=False)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (12): ReLU()\n",
      "  (13): Dropout(p=0.3, inplace=False)\n",
      "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "ConvNet\n",
      "ModuleList(\n",
      "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): Dropout(p=0.3, inplace=False)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): ReLU()\n",
      "  (8): Dropout(p=0.3, inplace=False)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (12): ReLU()\n",
      "  (13): Dropout(p=0.3, inplace=False)\n",
      "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "-----------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1/10, Batch : 1/49, Loss : 0.7013, Accuracy : 50.7812\n",
      "Epoch : 1/10, Batch : 26/49, Loss : 0.6825, Accuracy : 58.3984\n",
      "epoch loss 0.345010670190005\n",
      "epoch accuracy 0.57452\n",
      "Epoch : 2/10, Batch : 1/49, Loss : 0.6617, Accuracy : 64.8438\n",
      "Epoch : 2/10, Batch : 26/49, Loss : 0.6462, Accuracy : 68.1641\n",
      "epoch loss 0.3322585550780149\n",
      "epoch accuracy 0.63704\n",
      "Epoch : 3/10, Batch : 1/49, Loss : 0.6443, Accuracy : 64.2578\n",
      "Epoch : 3/10, Batch : 26/49, Loss : 0.6408, Accuracy : 64.6484\n",
      "epoch loss 0.32388947735127716\n",
      "epoch accuracy 0.66048\n",
      "Epoch : 4/10, Batch : 1/49, Loss : 0.6489, Accuracy : 61.5234\n",
      "Epoch : 4/10, Batch : 26/49, Loss : 0.6198, Accuracy : 70.3125\n",
      "epoch loss 0.317789346286931\n",
      "epoch accuracy 0.67896\n",
      "Epoch : 5/10, Batch : 1/49, Loss : 0.6287, Accuracy : 67.1875\n",
      "Epoch : 5/10, Batch : 26/49, Loss : 0.6157, Accuracy : 69.9219\n",
      "epoch loss 0.3127829358749783\n",
      "epoch accuracy 0.69768\n",
      "Epoch : 6/10, Batch : 1/49, Loss : 0.6142, Accuracy : 69.5312\n",
      "Epoch : 6/10, Batch : 26/49, Loss : 0.6134, Accuracy : 70.7031\n",
      "epoch loss 0.3094721682292899\n",
      "epoch accuracy 0.70872\n",
      "Epoch : 7/10, Batch : 1/49, Loss : 0.6067, Accuracy : 71.8750\n",
      "Epoch : 7/10, Batch : 26/49, Loss : 0.6173, Accuracy : 71.6797\n",
      "epoch loss 0.30754452144976746\n",
      "epoch accuracy 0.71724\n",
      "Epoch : 8/10, Batch : 1/49, Loss : 0.6067, Accuracy : 73.0469\n",
      "Epoch : 8/10, Batch : 26/49, Loss : 0.6230, Accuracy : 68.1641\n",
      "epoch loss 0.30570304455216396\n",
      "epoch accuracy 0.72364\n",
      "Epoch : 9/10, Batch : 1/49, Loss : 0.5997, Accuracy : 73.0469\n",
      "Epoch : 9/10, Batch : 26/49, Loss : 0.6120, Accuracy : 72.4609\n",
      "epoch loss 0.30519830504643547\n",
      "epoch accuracy 0.72452\n",
      "Epoch : 10/10, Batch : 1/49, Loss : 0.6141, Accuracy : 71.4844\n",
      "Epoch : 10/10, Batch : 26/49, Loss : 0.6018, Accuracy : 72.6562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/97 [00:17<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss 0.30469172271256595\n",
      "epoch accuracy 0.72648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#we will call the supervised training function for binary classification\n",
    "#we will build the parameters for the function\n",
    "#model\n",
    "model = Classifier(2)\n",
    "model_save_path = moco_pretrained_dir + '_supervised_binary_classifier'\n",
    "#call the function\n",
    "model = supervised_training(model, binary_label, model_save_path, epochs= super_epochs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 2: Multi-class Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_class_label(ip):\n",
    "    l = []\n",
    "    for x in ip:\n",
    "        if x in [6,2]:\n",
    "            l.append(0)\n",
    "        if x in [3,5]:\n",
    "            l.append(1)\n",
    "        if x in [4,7]:\n",
    "            l.append(2)\n",
    "        if x in [1,9]:\n",
    "            l.append(3)\n",
    "        if x in [0,8]:\n",
    "            l.append(4)\n",
    "        \n",
    "    return torch.tensor(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "ConvNet\n",
      "ModuleList(\n",
      "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): Dropout(p=0.3, inplace=False)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): ReLU()\n",
      "  (8): Dropout(p=0.3, inplace=False)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (12): ReLU()\n",
      "  (13): Dropout(p=0.3, inplace=False)\n",
      "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "ConvNet\n",
      "ModuleList(\n",
      "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): Dropout(p=0.3, inplace=False)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): ReLU()\n",
      "  (8): Dropout(p=0.3, inplace=False)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (12): ReLU()\n",
      "  (13): Dropout(p=0.3, inplace=False)\n",
      "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "-----------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1/10, Batch : 1/49, Loss : 1.6116, Accuracy : 20.8984\n",
      "Epoch : 1/10, Batch : 26/49, Loss : 1.6121, Accuracy : 20.3125\n",
      "epoch loss 0.8131457948193108\n",
      "epoch accuracy 0.21064\n",
      "Epoch : 2/10, Batch : 1/49, Loss : 1.6084, Accuracy : 21.6797\n",
      "Epoch : 2/10, Batch : 26/49, Loss : 1.6124, Accuracy : 20.3125\n",
      "epoch loss 0.8115099385841605\n",
      "epoch accuracy 0.22304\n",
      "Epoch : 3/10, Batch : 1/49, Loss : 1.6057, Accuracy : 22.2656\n",
      "Epoch : 3/10, Batch : 26/49, Loss : 1.6039, Accuracy : 22.0703\n",
      "epoch loss 0.8101080139887702\n",
      "epoch accuracy 0.23328\n",
      "Epoch : 4/10, Batch : 1/49, Loss : 1.6001, Accuracy : 25.3906\n",
      "Epoch : 4/10, Batch : 26/49, Loss : 1.6045, Accuracy : 22.2656\n",
      "epoch loss 0.8087335775807961\n",
      "epoch accuracy 0.2402\n",
      "Epoch : 5/10, Batch : 1/49, Loss : 1.6002, Accuracy : 23.4375\n",
      "Epoch : 5/10, Batch : 26/49, Loss : 1.6017, Accuracy : 25.0000\n",
      "epoch loss 0.8075221162481406\n",
      "epoch accuracy 0.25032\n",
      "Epoch : 6/10, Batch : 1/49, Loss : 1.6014, Accuracy : 22.2656\n",
      "Epoch : 6/10, Batch : 26/49, Loss : 1.6010, Accuracy : 23.0469\n",
      "epoch loss 0.8067029063234624\n",
      "epoch accuracy 0.25288\n",
      "Epoch : 7/10, Batch : 1/49, Loss : 1.5988, Accuracy : 22.6562\n",
      "Epoch : 7/10, Batch : 26/49, Loss : 1.5984, Accuracy : 26.1719\n",
      "epoch loss 0.8063400824045398\n",
      "epoch accuracy 0.25644\n",
      "Epoch : 8/10, Batch : 1/49, Loss : 1.5934, Accuracy : 26.3672\n",
      "Epoch : 8/10, Batch : 26/49, Loss : 1.5881, Accuracy : 27.5391\n",
      "epoch loss 0.8055658770590713\n",
      "epoch accuracy 0.2582\n",
      "Epoch : 9/10, Batch : 1/49, Loss : 1.5956, Accuracy : 25.5859\n",
      "Epoch : 9/10, Batch : 26/49, Loss : 1.5902, Accuracy : 27.5391\n",
      "epoch loss 0.8053302248728644\n",
      "epoch accuracy 0.26212\n",
      "Epoch : 10/10, Batch : 1/49, Loss : 1.5964, Accuracy : 26.1719\n",
      "Epoch : 10/10, Batch : 26/49, Loss : 1.5943, Accuracy : 26.3672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/97 [00:17<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss 0.8052204318882263\n",
      "epoch accuracy 0.26144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#we will call the supervised training function for multi-classification\n",
    "#we will build the parameters for the function\n",
    "#model\n",
    "model = Classifier(5)\n",
    "model_save_path = moco_pretrained_dir + '_supervised_five_class_classifier'\n",
    "#call the function\n",
    "model = supervised_training(model, five_class_label, model_save_path, epochs= super_epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#good learning rate for 10 class is :1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10) \n[GCC 10.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "079402cc50f681fca3bc4b588c8594ae5b0127c6215ec7c89d21fdfb87f97274"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
