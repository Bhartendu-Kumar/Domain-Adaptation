{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a Cycle-GAN for the pair of MNIST-USPS datasets. Use the\n",
    "# output of the converted target in the source classifier and report the result\n",
    "# on adaptation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in this script we will first implement a cycle gan\n",
    "#and then we will train a resnet50 based classifier on the source dataset\n",
    "#then using cyclegan we will translate the target dataset to source domain\n",
    "#and then use the trained clssifier to classify the translated target dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the cycle gan follows the implementation from the paper: Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks by Zhu et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'mnist_cycle_adaptation'\n",
    "version = 'v0'\n",
    "\n",
    "#concat experiment name and version to get experiment id\n",
    "experiment_id = experiment_name + '_' + version\n",
    "\n",
    "model_path = 'saved_models/cycle_gan'\n",
    "\n",
    "results_path = 'Results/cycle_gan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU name\n",
    "#\n",
    "GPU_NAME = 'cuda:1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neceassary imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable, Function\n",
    "# from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "import torch.utils.data as data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#import utils\n",
    "import os\n",
    "import itertools\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports for visualizations\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 13:01:34.174401: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchvision.io import read_image\n",
    "from torchsummary import summary\n",
    "#import tenserboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "#initialize tensorboard writer\n",
    "#create writer for tensorboard\n",
    "writer = SummaryWriter(f'runs/'+experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enable cudnn\n",
    "cudnn.benchmark = True\n",
    "#cuda cache clear\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#set random seed\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#device\n",
    "device = torch.device(GPU_NAME if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the hyperparameters\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 1\n",
    "NUM_EPOCHS_PRETRAINING = 5\n",
    "\n",
    "LOAD_MODEL = False\n",
    "\n",
    "#WHGAN parameters\n",
    "NUM_EPOCHS_GAN = 1\n",
    "CRITIC_ITERATIONS = 5\n",
    "LEARNING_RATE_GAN = 1e-4\n",
    "LAMBDA_GP = 10\n",
    "CYCLE_LOSS_WEIGHT =1\n",
    "\n",
    "\n",
    "IMAGE_SIZE = 224\n",
    "CHANNELS_IMG = 1\n",
    "A_Channels = 1\n",
    "B_Channels = 1\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "\n",
    "#parameters of ADAM optimizer\n",
    "LEARNING_RATE = 0.001\n",
    "BETA_1 = 0.9\n",
    "BETA_2 = 0.999\n",
    "\n",
    "#parameters of SGD optimizer with momentum\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### utility functions #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(a, b, ab_gen, ba_gen, samples_path = results_path, epoch=0):\n",
    "    ab_gen.eval()\n",
    "    ba_gen.eval()\n",
    "\n",
    "    b_fake = ab_gen(a)\n",
    "    a_fake = ba_gen(b)\n",
    "\n",
    "    a_imgs = torch.zeros((a.shape[0] * 2, 3, a.shape[2], a.shape[3]))\n",
    "    b_imgs = torch.zeros((b.shape[0] * 2, 3, b.shape[2], b.shape[3]))\n",
    "\n",
    "    even_idx = torch.arange(start=0, end=a.shape[0] * 2, step=2)\n",
    "    odd_idx = torch.arange(start=1, end=a.shape[0] * 2, step=2)\n",
    "\n",
    "    a_imgs[even_idx] = a.cpu()\n",
    "    a_imgs[odd_idx] = b_fake.cpu()\n",
    "\n",
    "    b_imgs[even_idx] = b.cpu()\n",
    "    b_imgs[odd_idx] = a_fake.cpu()\n",
    "\n",
    "    rows = math.ceil((a.shape[0] * 2) ** 0.5)\n",
    "    a_imgs_ = vutils.make_grid(a_imgs, normalize=True, nrow=rows)\n",
    "    b_imgs_ = vutils.make_grid(b_imgs, normalize=True, nrow=rows)\n",
    "\n",
    "    vutils.save_image(a_imgs_, os.path.join(samples_path, 'a2b_' + str(epoch) + '.png'))\n",
    "    vutils.save_image(b_imgs_, os.path.join(samples_path, 'b2a_' + str(epoch) + '.png'))\n",
    "\n",
    "    #plot the images on tensorboard\n",
    "    writer.add_image('a2b', a_imgs_, epoch)\n",
    "    writer.add_image('b2a', b_imgs_, epoch)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cycle-GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### the model architectures for CycleGan was inspired from github repo :  https://github.com/s-chh/Pytorch-CycleGAN-Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will have both Generator and Discriminator inspired from Resnet50 based architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we define TWO main architectural blocks of the generator and discriminator: Convolutional Block and Residual Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we define the general convolutional block, which is used in both generator and discriminator\n",
    "#convolutional block is a function which takes in the number of input channels, number of output channels, kernel size, stride, padding and whether to use batch normalization or not and transpose convolution or not\n",
    "#and returns a nn.Sequential object which contains the convolutional block\n",
    "def ConvolutionalBlock(in_channels, out_channels, kernel_size = 4, stride = 2, padding = 1, use_batchnorm=True, use_transpose=False):\n",
    "    block = []\n",
    "    if use_transpose:\n",
    "        block.append(nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias = not use_batchnorm))\n",
    "    else:\n",
    "        block.append(nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias = not use_batchnorm))\n",
    "    if use_batchnorm:\n",
    "        block.append(nn.BatchNorm2d(out_channels))\n",
    "        #return\n",
    "    return nn.Sequential(*block)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we definr residual block as a class\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv_block1 = ConvolutionalBlock(channels, channels, kernel_size = 3, stride = 1, padding = 1, use_batchnorm = True)\n",
    "        self.conv_block2 = ConvolutionalBlock(channels, channels, kernel_size = 3, stride = 1, padding = 1, use_batchnorm = True)\n",
    "        #def call\n",
    "    def __call__(self, x):\n",
    "        x = F.relu(self.conv_block1(x))\n",
    "        return x + self.conv_block2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function fror initializing the weights of the model\n",
    "def weights_init(model):\n",
    "    for m in model.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "                nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1, conv_dim=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.conv1 = ConvolutionalBlock(in_channels, conv_dim, kernel_size = 5, stride = 1, padding = 2, use_batchnorm = True)\n",
    "        self.conv2 = ConvolutionalBlock(conv_dim, conv_dim*2, kernel_size = 3, stride = 2, padding = 1, use_batchnorm = True)\n",
    "        self.conv3 = ConvolutionalBlock(conv_dim*2, conv_dim*4, kernel_size = 3, stride = 2, padding = 1, use_batchnorm = True)\n",
    "        self.residual_block1 = ResidualBlock(conv_dim*4)\n",
    "        self.trans_conv1 = ConvolutionalBlock(conv_dim*4, conv_dim*2, kernel_size = 3, stride = 1, padding = 1, use_batchnorm = True, use_transpose = True)\n",
    "        self.trans_conv2 = ConvolutionalBlock(conv_dim*2, conv_dim, kernel_size = 3, stride = 2, padding = 1, use_batchnorm = True, use_transpose = True)\n",
    "        self.conv4 = ConvolutionalBlock(conv_dim, out_channels, kernel_size = 5, stride = 1, padding = 2, use_batchnorm = False)\n",
    "\n",
    "        #initialize weights\n",
    "        self.apply(weights_init)\n",
    "\n",
    "        #forward\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.residual_block1(x))\n",
    "        x = F.relu(self.trans_conv1(x))\n",
    "        x = F.relu(self.trans_conv2(x))\n",
    "        x = torch.tanh(self.conv4(x))\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels=1, conv_dim=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1 = ConvolutionalBlock(channels, conv_dim, use_batchnorm = False)\n",
    "        self.conv2 = ConvolutionalBlock(conv_dim, conv_dim*2)\n",
    "        self.conv3 = ConvolutionalBlock(conv_dim*2, conv_dim*4)\n",
    "        self.conv4 = ConvolutionalBlock(conv_dim*4, 1, kernel_size = 3, stride = 1, padding = 1, use_batchnorm = False)\n",
    "\n",
    "        #initialize weights\n",
    "        self.apply(weights_init)\n",
    "    #forward\n",
    "\n",
    "    def forward(self, x):\n",
    "        alpha = 0.2\n",
    "        x = F.leaky_relu(self.conv1(x), alpha)\n",
    "        x = F.leaky_relu(self.conv2(x), alpha)\n",
    "        x = F.leaky_relu(self.conv3(x), alpha)\n",
    "        x = self.conv4(x)\n",
    "        x = x.reshape([x.shape[0], -1]).mean(1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first create generators\n",
    "#we create generators for both the domains\n",
    "#first from source domain to target domain\n",
    "generator_source_to_target = Generator(in_channels=A_Channels, out_channels=B_Channels)\n",
    "#then from target domain to source domain\n",
    "generator_target_to_source = Generator(in_channels=A_Channels, out_channels=B_Channels)\n",
    "\n",
    "#now define the discriminators\n",
    "#first for the source domain\n",
    "discriminator_source = Discriminator(channels=A_Channels)\n",
    "#then for the target domain\n",
    "discriminator_target = Discriminator(channels=B_Channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define transforms\n",
    "#define the transform for the dataset\n",
    "mean = np.array([0.5])\n",
    "std = np.array([0.5])\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "  \n",
    "    # if torch tensor then leave as it is, else convert to tensor\n",
    "    transforms.Lambda(lambda x: x if isinstance(x, torch.Tensor) else transforms.functional.to_tensor(x)),\n",
    "    #\n",
    "\n",
    "    #resize to 224x224\n",
    "    transforms.Resize([IMAGE_SIZE, IMAGE_SIZE]),\n",
    "\n",
    "\n",
    "    # normalize\n",
    "    transforms.Normalize(mean, std),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### source data - MNIST\n",
    "#### target data - USPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load train data\n",
    "source_data = datasets.MNIST(root='./data/', download=True, transform=transform) \n",
    "#load train data\n",
    "source_loader = torch.utils.data.DataLoader(dataset=source_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=8, drop_last=True)\n",
    "                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#load test data\n",
    "#USPS dataset\n",
    "target_data = datasets.USPS(root='./data/', download=True, transform=transform)\n",
    "#load test data\n",
    "target_loader = torch.utils.data.DataLoader(dataset=target_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=8, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cycle gan training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we define a funcrion which will train our cycle gan\n",
    "#this function will take as input: the generators, the discriminators, the source and target dataloaders, the number of epochs, the learning rate, the weight of the cycle consistency loss, the weight of the identity loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will write losses and accuracies to tensorboard\n",
    "#we will also plot the images generated by the generators to tensorboard\n",
    "def train_cycle_gan(generator_source_to_target, generator_target_to_source, discriminator_source, discriminator_target, source_loader, target_loader, num_epochs= NUM_EPOCHS_GAN):\n",
    "    #define optimizers\n",
    "    #we will use Adam optimizer for all the models\n",
    "    generator_optimizer = torch.optim.Adam(list(generator_source_to_target.parameters()) + list(generator_target_to_source.parameters()), lr=0.0002, betas=(0.5, 0.999), weight_decay=2e-5)\n",
    "    discriminator_optimizer = torch.optim.Adam(list(discriminator_source.parameters()) + list(discriminator_target.parameters()), lr=0.0002, betas=(0.5, 0.999), weight_decay=2e-5)\n",
    "\n",
    "    iters_per_epoch = min(len(source_loader), len(target_loader)) \n",
    "\n",
    "    # Fix images for vizibility and plotting purposes to tensorboard\n",
    "    source_fixed = iter(source_loader).next()[0]\n",
    "    target_fixed = iter(target_loader).next()[0]\n",
    "\n",
    "    #send the models to gpu\n",
    "    generator_source_to_target = generator_source_to_target.to(device)\n",
    "    generator_target_to_source = generator_target_to_source.to(device)\n",
    "    discriminator_source = discriminator_source.to(device)\n",
    "    discriminator_target = discriminator_target.to(device)\n",
    "\n",
    "    #send the fixed images to gpu\n",
    "    source_fixed = source_fixed.to(device)\n",
    "    target_fixed = target_fixed.to(device)\n",
    "\n",
    "    tensorboard_step = 0\n",
    "\n",
    "    #iterate for the number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        #have all models train mode\n",
    "        generator_source_to_target.train()\n",
    "        generator_target_to_source.train()\n",
    "        discriminator_source.train()\n",
    "        discriminator_target.train()\n",
    "\n",
    "        #iterate through the datasets, we combine both by zip and enumerate\n",
    "        for i, (source, target) in enumerate(zip(source_loader, target_loader)):\n",
    "\n",
    "            #we do not need labels for the cycle gan\n",
    "            #so load the images\n",
    "            source_real , _ = source\n",
    "            #move to gpu\n",
    "            source_real = source_real.to(device)\n",
    "            target_real , _ = target\n",
    "            #move to gpu\n",
    "            target_real = target_real.to(device)\n",
    "\n",
    "            #fake images\n",
    "            #we will generate fake images from the real images\n",
    "            source_fake = generator_target_to_source(target_real)\n",
    "            target_fake = generator_source_to_target(source_real)   \n",
    "\n",
    "            #training the discriminators\n",
    "            #we will train the discriminators to distinguish between real and fake images\n",
    "            source_real_discriminator_output = discriminator_source(source_real)\n",
    "            source_fake_discriminator_output = discriminator_source(source_fake.detach())\n",
    "            #loss for the source domain\n",
    "            source_discriminator_loss = (torch.mean((source_real_discriminator_output - 1)**2) + torch.mean(source_fake_discriminator_output**2))/2\n",
    "\n",
    "            target_real_discriminator_output = discriminator_target(target_real)\n",
    "            target_fake_discriminator_output = discriminator_target(target_fake.detach())\n",
    "            #loss for the target domain\n",
    "            target_discriminator_loss = (torch.mean((target_real_discriminator_output - 1)**2) + torch.mean(target_fake_discriminator_output**2))/2\n",
    "\n",
    "            #sum the losses to get the total loss\n",
    "            discriminator_loss = source_discriminator_loss + target_discriminator_loss\n",
    "\n",
    "            #apply zero_grad to the optimizers\n",
    "            discriminator_optimizer.zero_grad()\n",
    "            #backpropagate the loss\n",
    "            discriminator_loss.backward()\n",
    "            #update the parameters\n",
    "            discriminator_optimizer.step()\n",
    "\n",
    "            #write the losses to tensorboard\n",
    "            writer.add_scalar('BATCH_Total_Discriminator_Loss', discriminator_loss, tensorboard_step)\n",
    "            writer.add_scalar('BATCH_Source_Discriminator_Loss', source_discriminator_loss, tensorboard_step)\n",
    "            writer.add_scalar('BATCH_Target_Discriminator_Loss', target_discriminator_loss, tensorboard_step)\n",
    "\n",
    "\n",
    "\n",
    "            #training the generators\n",
    "            #we will train the generators to fool the discriminators\n",
    "            #we will also train the generators to preserve the identity of the images\n",
    "            #we will also train the generators to preserve the cycle consistency\n",
    "            #we will train the generators to minimize the adversarial loss\n",
    "\n",
    "            source_fake_generator_output = discriminator_source(source_fake)\n",
    "            target_fake_generator_output = discriminator_target(target_fake)\n",
    "\n",
    "            #adversarial loss\n",
    "            source_generator_loss = torch.mean((source_fake_generator_output - 1)**2)\n",
    "            target_generator_loss = torch.mean((target_fake_generator_output - 1)**2)\n",
    "            #sum the losses to get the total loss\n",
    "            generator_loss = source_generator_loss + target_generator_loss\n",
    "\n",
    "            #cycle consistency loss\n",
    "            source_generator_cycle_consistency_loss = (source_real - generator_target_to_source(target_fake)).abs().mean()\n",
    "            target_generator_cycle_consistency_loss = (target_real - generator_source_to_target(source_fake)).abs().mean()\n",
    "            #sum the losses to get the total loss\n",
    "            generator_cycle_consistency_loss = source_generator_cycle_consistency_loss + target_generator_cycle_consistency_loss\n",
    "\n",
    "            cycle_gan_loss = generator_loss + CYCLE_LOSS_WEIGHT * generator_cycle_consistency_loss\n",
    "\n",
    "            #zero_grad the optimizers\n",
    "            generator_optimizer.zero_grad()\n",
    "            #backpropagate the loss\n",
    "            cycle_gan_loss.backward()\n",
    "            #update the parameters\n",
    "            generator_optimizer.step()\n",
    "\n",
    "            #write the losses to tensorboard\n",
    "            writer.add_scalar('BATCH_Total_Generator_Loss', cycle_gan_loss, tensorboard_step)\n",
    "            writer.add_scalar('BATCH_Source_Generator_Loss', source_generator_loss, tensorboard_step)\n",
    "            writer.add_scalar('BATCH_Target_Generator_Loss', target_generator_loss, tensorboard_step)\n",
    "            writer.add_scalar('BATCH_Cycle_Consistency_Loss', generator_cycle_consistency_loss, tensorboard_step)\n",
    "            #cycle gan loss\n",
    "            writer.add_scalar('BATCH_Cycle_GAN_Loss', cycle_gan_loss, tensorboard_step)\n",
    "\n",
    "            #print the losses if the iteration is a multiple of 100\n",
    "            if i % 100 == 0:\n",
    "                #print all the losses\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Discriminator Loss: {:.4f}, Generator Loss: {:.4f}, Cycle Consistency Loss: {:.4f}, Cycle GAN Loss: {:.4f}'\n",
    "                        .format(epoch+1, num_epochs, i+1, len(source_loader), discriminator_loss.item(), generator_loss.item(), generator_cycle_consistency_loss.item(), cycle_gan_loss.item()))\n",
    "                \n",
    "                    \n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #we will update teensorboard steps\n",
    "            tensorboard_step += 1\n",
    "\n",
    "        #we will save the models after every epoch\n",
    "        torch.save(generator_source_to_target.state_dict(), os.path.join(model_path, 'generator_source_to_target_{}.pth'.format(epoch+1)))\n",
    "        torch.save(generator_target_to_source.state_dict(), os.path.join(model_path, 'generator_target_to_source_{}.pth'.format(epoch+1)))\n",
    "        torch.save(discriminator_source.state_dict(), os.path.join(model_path, 'discriminator_source_{}.pth'.format(epoch+1)))\n",
    "        torch.save(discriminator_target.state_dict(), os.path.join(model_path, 'discriminator_target_{}.pth'.format(epoch+1)))\n",
    "        #write images fixed to tensorboard\n",
    "        writer.add_image('Source_Real', torchvision.utils.make_grid(source_real.cpu().data, normalize=True), epoch+1)\n",
    "        writer.add_image('Source_Fake', torchvision.utils.make_grid(source_fake.cpu().data, normalize=True), epoch+1)\n",
    "        writer.add_image('Target_Real', torchvision.utils.make_grid(target_real.cpu().data, normalize=True), epoch+1)\n",
    "        writer.add_image('Target_Fake', torchvision.utils.make_grid(target_fake.cpu().data, normalize=True), epoch+1)\n",
    "\n",
    "        #pass arguments to the function generate images\n",
    "        generate_images(source_fixed, target_fixed, generator_source_to_target, generator_target_to_source, results_path, epoch=epoch+1)\n",
    "\n",
    "    #generate the final images\n",
    "    generate_images(source_fixed, target_fixed, generator_source_to_target, generator_target_to_source, results_path)\n",
    "\n",
    "    #return the models\n",
    "    return generator_source_to_target, generator_target_to_source, discriminator_source, discriminator_target\n",
    "        \n",
    "   \n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "      \n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (32) must match the size of tensor b (7) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/lisa/bhartendu/adrl/A2/Domaain_Adaptation/cycle_gan_based_domain_adaptation.ipynb Cell 37\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A2/Domaain_Adaptation/cycle_gan_based_domain_adaptation.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#call the function on the models and the dataloaders and get the models back\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A2/Domaain_Adaptation/cycle_gan_based_domain_adaptation.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m generator_source_to_target, generator_target_to_source, discriminator_source, discriminator_target \u001b[39m=\u001b[39m train_cycle_gan(generator_source_to_target, generator_target_to_source, discriminator_source, discriminator_target, source_loader, target_loader)\n",
      "\u001b[1;32m/home/lisa/bhartendu/adrl/A2/Domaain_Adaptation/cycle_gan_based_domain_adaptation.ipynb Cell 37\u001b[0m in \u001b[0;36mtrain_cycle_gan\u001b[0;34m(generator_source_to_target, generator_target_to_source, discriminator_source, discriminator_target, source_loader, target_loader, num_epochs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A2/Domaain_Adaptation/cycle_gan_based_domain_adaptation.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=94'>95</a>\u001b[0m generator_loss \u001b[39m=\u001b[39m source_generator_loss \u001b[39m+\u001b[39m target_generator_loss\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A2/Domaain_Adaptation/cycle_gan_based_domain_adaptation.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=96'>97</a>\u001b[0m \u001b[39m#cycle consistency loss\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A2/Domaain_Adaptation/cycle_gan_based_domain_adaptation.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=97'>98</a>\u001b[0m source_generator_cycle_consistency_loss \u001b[39m=\u001b[39m (source_real \u001b[39m-\u001b[39;49m generator_target_to_source(target_fake))\u001b[39m.\u001b[39mabs()\u001b[39m.\u001b[39mmean()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A2/Domaain_Adaptation/cycle_gan_based_domain_adaptation.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=98'>99</a>\u001b[0m target_generator_cycle_consistency_loss \u001b[39m=\u001b[39m (target_real \u001b[39m-\u001b[39m generator_source_to_target(source_fake))\u001b[39m.\u001b[39mabs()\u001b[39m.\u001b[39mmean()\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/A2/Domaain_Adaptation/cycle_gan_based_domain_adaptation.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=99'>100</a>\u001b[0m \u001b[39m#sum the losses to get the total loss\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (32) must match the size of tensor b (7) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "#call the function on the models and the dataloaders and get the models back\n",
    "generator_source_to_target, generator_target_to_source, discriminator_source, discriminator_target = train_cycle_gan(generator_source_to_target, generator_target_to_source, discriminator_source, discriminator_target, source_loader, target_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pretraining part "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this part we will train a resnet50 based classifier on source data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Step 1: Initialize model with the best available weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the model\n",
    "weights = ResNet50_Weights.DEFAULT\n",
    "#send weight sto gpu\n",
    "# weights = weights.to(device)\n",
    "#sending the model to GPU\n",
    "\n",
    "model = resnet50(weights=weights).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print model summary\n",
    "summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10) \n[GCC 10.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "079402cc50f681fca3bc4b588c8594ae5b0127c6215ec7c89d21fdfb87f97274"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
