{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in this notebook we will implement MOCO paper:\n",
    "#https://arxiv.org/pdf/1911.05722.pdf\n",
    "#CNN architecture we change, but MOCO loss function is the same, and training is the same\n",
    "#we use 5 different data gmentations (rotations, blur, color distortion, cropping and resizing) for defining the positive samples\n",
    "\n",
    "#training is done on 1 GPU, training setting are:\n",
    "#1. Use the entire training data to learn the representations.\n",
    "#2. Once the representations are learned, use a linear and logistic layers and retrain with 10-50% of supervised training data.\n",
    "#3. Experiment with two different sizes for the encoder dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 0\n",
    "experiment = 'moco'\n",
    "experiment_name = experiment + '_' + str(version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "\n",
    "from functools import partial\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "#tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'config' from '/home/lisa/bhartendu/adrl/A3/config.py'>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "import models\n",
    "importlib.reload(models)\n",
    "from models import  pentaClassifier, binaryClassifier, baseClassifier, convNet\n",
    "\n",
    "\n",
    "import config\n",
    "from config import cfg\n",
    "importlib.reload(config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed\n",
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "# Torch RNG\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HYPER - PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = 'results/'\n",
    "moco_pretrained_dir = results_dir+'model_'+experiment_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MOCO - HYPER - PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "moco_dim = 512\n",
    "moco_k = 4096\n",
    "moco_m = 0.99\n",
    "moco_t = 0.07\n",
    "moco_loss_symmetric = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MOCO - TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.06\n",
    "epochs = 200  # 200\n",
    "batch_size = 512\n",
    "schedule = [120, 160]\n",
    "wd = 5e-4\n",
    "cos = True      # cosine lr schedule\n",
    "bn_splits = 8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supervised - Hyper - Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_training_data = 0.50"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supervised Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_lr = 5.0\n",
    "super_epochs = 10\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data-loader\n",
    "\n",
    "#### Adapted from pytorch code of Contrastive learning libs: http://github.com/zhirongw/lemniscate.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "class CIFAR10Pair(CIFAR10):\n",
    "    \"\"\"CIFAR10 Dataset.\n",
    "    \"\"\"\n",
    "    def __getitem__(self, index):\n",
    "        img = self.data[index]\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            im_1 = self.transform(img)\n",
    "            im_2 = self.transform(img)\n",
    "\n",
    "        return im_1, im_2\n",
    "\n",
    "# train_transform = transforms.Compose([\n",
    "#     transforms.RandomResizedCrop(32),\n",
    "#     transforms.RandomHorizontalFlip(p=0.5),\n",
    "#     transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "#     transforms.RandomGrayscale(p=0.2),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "#we will aplly 5 different data gmentations (rotations, blur, color distortion, cropping and resizing) for defining the positive samples\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(32),\n",
    "    #random rotation with random angle\n",
    "    transforms.RandomRotation([-1* torch.rand(1)*360 , torch.rand(1)*360]),\n",
    "    #random blur\n",
    "    transforms.RandomApply([transforms.GaussianBlur(3, sigma=[0.1, 2.0])], p=0.5),\n",
    "    #random color distortion\n",
    "    transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "    \n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "\n",
    "# data prepare\n",
    "train_data = CIFAR10Pair(root='data', train=True, transform=train_transform, download=True)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True, drop_last=True)\n",
    "\n",
    "memory_data = CIFAR10(root='data', train=True, transform=test_transform, download=True)\n",
    "memory_loader = DataLoader(memory_data, batch_size=batch_size, shuffle=False, num_workers=16, pin_memory=True)\n",
    "\n",
    "test_data = CIFAR10(root='data', train=False, transform=test_transform, download=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=16, pin_memory=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Batch implementation adapted from: \n",
    "#### https://github.com/davidcpage/cifar10-fast/blob/master/torch_backend.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitBatchNorm(nn.BatchNorm2d):\n",
    "    def __init__(self, num_features, num_splits= bn_splits, **kw):\n",
    "        super().__init__(num_features, **kw)\n",
    "        self.num_splits = num_splits\n",
    "        \n",
    "    def forward(self, input):\n",
    "        N, C, H, W = input.shape\n",
    "        if self.training or not self.track_running_stats:\n",
    "            running_mean_split = self.running_mean.repeat(self.num_splits)\n",
    "            running_var_split = self.running_var.repeat(self.num_splits)\n",
    "            outcome = nn.functional.batch_norm(\n",
    "                input.view(-1, C * self.num_splits, H, W), running_mean_split, running_var_split, \n",
    "                self.weight.repeat(self.num_splits), self.bias.repeat(self.num_splits),\n",
    "                True, self.momentum, self.eps).view(N, C, H, W)\n",
    "            self.running_mean.data.copy_(running_mean_split.view(self.num_splits, C).mean(dim=0))\n",
    "            self.running_var.data.copy_(running_var_split.view(self.num_splits, C).mean(dim=0))\n",
    "            return outcome\n",
    "        else:\n",
    "            return nn.functional.batch_norm(\n",
    "                input, self.running_mean, self.running_var, \n",
    "                self.weight, self.bias, False, self.momentum, self.eps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the following class was adapted from facebookresearch/moco which replaces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #write a function to replace all the batchnorm layers with splitbatchnorm layers if bn_splits > 1\n",
    "# def replace_bn(model, num_splits):\n",
    "#     #if num_splits is 1, then return the model\n",
    "#     if num_splits == 1:\n",
    "#         return model\n",
    "#     norm_layer = partial(SplitBatchNorm, num_splits=bn_splits) if bn_splits > 1 else nn.BatchNorm2d\n",
    "#     for name, child in model.named_children():\n",
    "#         if isinstance(child, nn.BatchNorm2d):\n",
    "#             setattr(model, name, norm_layer(child.num_features))\n",
    "#         else:\n",
    "#             replace_bn(child, num_splits)\n",
    "#     return model\n",
    "    \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to use the class SplitBatchNorm to replace the batchnorm layers with splitbatchnorm layers if bn_splits > 1\n",
    "#the init has num_features and num_splits as arguments, thus while changing the batchnorm layers to splitbatchnorm layers, we need to pass the num_splits as an argument\n",
    "def replace_bn(model, num_splits):\n",
    "    #if num_splits is 1, then return the model\n",
    "    if num_splits == 1:\n",
    "        return model\n",
    "    #loop through the model and replace the batchnorm layers with splitbatchnorm layers using the class SplitBatchNorm\n",
    "    norm_layer = partial(SplitBatchNorm, num_splits=bn_splits)\n",
    "    for name, child in model.named_children():\n",
    "        if isinstance(child, nn.BatchNorm2d):\n",
    "            #change the batchnorm layers to splitbatchnorm layers by the return of the function : SplitBatchNorm(child.num_features, num_splits)\n",
    "            #replace batchnorm with norm_layer\n",
    "            setattr(model, name, norm_layer(child.num_features))\n",
    "        else:\n",
    "            replace_bn(child, num_splits)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a model class named ModelBAse that will have the exact same architecture as the convNet class but will flatten the output of the model, to get embedding of the model\n",
    "class ModelBase(nn.Module):\n",
    "    def __init__(self, cfg=cfg['model'], device=device):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.device = device\n",
    "        self.conv = convNet(cfg, device=device)\n",
    "        self.flat = nn.Flatten()\n",
    "        self.fc = nn.Linear(moco_dim, moco_dim)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flat(self.conv(x))\n",
    "        #pass the output of the model through a linear layer\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "ConvNet\n",
      "ModuleList(\n",
      "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): Dropout(p=0.3, inplace=False)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): ReLU()\n",
      "  (8): Dropout(p=0.3, inplace=False)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (12): ReLU()\n",
      "  (13): Dropout(p=0.3, inplace=False)\n",
      "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#buils an object of the ModelBase class\n",
    "model = ModelBase()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 30, 30]             864\n",
      "       BatchNorm2d-2           [-1, 32, 30, 30]              64\n",
      "              ReLU-3           [-1, 32, 30, 30]               0\n",
      "           Dropout-4           [-1, 32, 30, 30]               0\n",
      "         MaxPool2d-5           [-1, 32, 15, 15]               0\n",
      "            Conv2d-6           [-1, 64, 13, 13]          18,432\n",
      "       BatchNorm2d-7           [-1, 64, 13, 13]             128\n",
      "              ReLU-8           [-1, 64, 13, 13]               0\n",
      "           Dropout-9           [-1, 64, 13, 13]               0\n",
      "        MaxPool2d-10             [-1, 64, 6, 6]               0\n",
      "           Conv2d-11            [-1, 128, 4, 4]          73,728\n",
      "      BatchNorm2d-12            [-1, 128, 4, 4]             256\n",
      "             ReLU-13            [-1, 128, 4, 4]               0\n",
      "          Dropout-14            [-1, 128, 4, 4]               0\n",
      "        MaxPool2d-15            [-1, 128, 2, 2]               0\n",
      "          convNet-16            [-1, 128, 2, 2]               0\n",
      "          Flatten-17                  [-1, 512]               0\n",
      "           Linear-18                  [-1, 512]         262,656\n",
      "================================================================\n",
      "Total params: 356,128\n",
      "Trainable params: 356,128\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.36\n",
      "Params size (MB): 1.36\n",
      "Estimated Total Size (MB): 2.73\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#summary of the model\n",
    "summary(model, input_size=(3, 32, 32), device='cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------\n",
    "---------------------------------------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOCO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### defininng MOCO Training Routine: Including the queue and the memory bank and key encoder, query encoder\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelMoCo(nn.Module):\n",
    "    def __init__(self, dim=moco_dim, K=moco_k, m=moco_m, T=moco_t, bn_splits=bn_splits, symmetric=True):\n",
    "        super(ModelMoCo, self).__init__()\n",
    "\n",
    "        self.K = K\n",
    "        self.m = m\n",
    "        self.T = T\n",
    "        self.symmetric = symmetric\n",
    "\n",
    "        # create the encoders\n",
    "        self.encoder_q = ModelBase()\n",
    "        self.encoder_k = ModelBase()\n",
    "\n",
    "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
    "            param_k.data.copy_(param_q.data)  # initialize\n",
    "            param_k.requires_grad = False  # not update by gradient\n",
    "\n",
    "        # create the queue\n",
    "        self.register_buffer(\"queue\", torch.randn(dim, K))\n",
    "        self.queue = nn.functional.normalize(self.queue, dim=0)\n",
    "\n",
    "        self.register_buffer(\"queue_ptr\", torch.zeros(1, dtype=torch.long))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _momentum_update_key_encoder(self):\n",
    "        \"\"\"\n",
    "        Momentum update of the key encoder\n",
    "        \"\"\"\n",
    "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
    "            param_k.data = param_k.data * self.m + param_q.data * (1. - self.m)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _dequeue_and_enqueue(self, keys):\n",
    "        batch_size = keys.shape[0]\n",
    "\n",
    "        ptr = int(self.queue_ptr)\n",
    "        assert self.K % batch_size == 0  # for simplicity\n",
    "\n",
    "        # replace the keys at ptr (dequeue and enqueue)\n",
    "        self.queue[:, ptr:ptr + batch_size] = keys.t()  # transpose\n",
    "        ptr = (ptr + batch_size) % self.K  # move pointer\n",
    "\n",
    "        self.queue_ptr[0] = ptr\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _batch_shuffle_single_gpu(self, x):\n",
    "        \"\"\"\n",
    "        Batch shuffle, for making use of BatchNorm.\n",
    "        \"\"\"\n",
    "        # random shuffle index\n",
    "        idx_shuffle = torch.randperm(x.shape[0]).cuda()\n",
    "\n",
    "        # index for restoring\n",
    "        idx_unshuffle = torch.argsort(idx_shuffle)\n",
    "\n",
    "        return x[idx_shuffle], idx_unshuffle\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _batch_unshuffle_single_gpu(self, x, idx_unshuffle):\n",
    "        \"\"\"\n",
    "        Undo batch shuffle.\n",
    "        \"\"\"\n",
    "        return x[idx_unshuffle]\n",
    "\n",
    "    def contrastive_loss(self, im_q, im_k):\n",
    "        # compute query features\n",
    "        q = self.encoder_q(im_q)  # queries: NxC\n",
    "        q = nn.functional.normalize(q, dim=1)  # already normalized\n",
    "\n",
    "        # compute key features\n",
    "        with torch.no_grad():  # no gradient to keys\n",
    "            # shuffle for making use of BN\n",
    "            im_k_, idx_unshuffle = self._batch_shuffle_single_gpu(im_k)\n",
    "\n",
    "            k = self.encoder_k(im_k_)  # keys: NxC\n",
    "            k = nn.functional.normalize(k, dim=1)  # already normalized\n",
    "\n",
    "            # undo shuffle\n",
    "            k = self._batch_unshuffle_single_gpu(k, idx_unshuffle)\n",
    "\n",
    "        # compute logits\n",
    "        # Einstein sum is more intuitive\n",
    "        # positive logits: Nx1\n",
    "        l_pos = torch.einsum('nc,nc->n', [q, k]).unsqueeze(-1)\n",
    "        # negative logits: NxK\n",
    "        l_neg = torch.einsum('nc,ck->nk', [q, self.queue.clone().detach()])\n",
    "\n",
    "        # logits: Nx(1+K)\n",
    "        logits = torch.cat([l_pos, l_neg], dim=1)\n",
    "\n",
    "        # apply temperature\n",
    "        logits /= self.T\n",
    "\n",
    "        # labels: positive key indicators\n",
    "        labels = torch.zeros(logits.shape[0], dtype=torch.long).cuda()\n",
    "        \n",
    "        loss = nn.CrossEntropyLoss().cuda()(logits, labels)\n",
    "\n",
    "        return loss, q, k\n",
    "\n",
    "    def forward(self, im1, im2):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            im_q: a batch of query images\n",
    "            im_k: a batch of key images\n",
    "        Output:\n",
    "            loss\n",
    "        \"\"\"\n",
    "\n",
    "        # update the key encoder\n",
    "        with torch.no_grad():  # no gradient to keys\n",
    "            self._momentum_update_key_encoder()\n",
    "\n",
    "        # compute loss\n",
    "        if self.symmetric:  # asymmetric loss\n",
    "            loss_12, q1, k2 = self.contrastive_loss(im1, im2)\n",
    "            loss_21, q2, k1 = self.contrastive_loss(im2, im1)\n",
    "            loss = loss_12 + loss_21\n",
    "            k = torch.cat([k1, k2], dim=0)\n",
    "        else:  # asymmetric loss\n",
    "            loss, q, k = self.contrastive_loss(im1, im2)\n",
    "\n",
    "        self._dequeue_and_enqueue(k)\n",
    "\n",
    "        return loss\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer: SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### learning rate schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr scheduler for training\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Decay the learning rate based on schedule\"\"\"\n",
    "    learning_rate = lr \n",
    "    if cos:  # cosine lr schedule\n",
    "        learning_rate *= 0.5 * (1. + math.cos(math.pi * epoch / epochs))\n",
    "    else:  # stepwise lr schedule\n",
    "        for milestone in schedule:\n",
    "            learning_rate *= 0.1 if epoch >= milestone else 1.\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = learning_rate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-03 12:31:34.159879: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "# train for one epoch\n",
    "#create batch writer\n",
    "batch_writer = SummaryWriter(f'{results_dir}/run/')\n",
    "batch_count = 0\n",
    "\n",
    "\n",
    "def train(net, data_loader, train_optimizer, epoch):\n",
    "    net.train()\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    total_loss, total_num, train_bar = 0.0, 0, tqdm(data_loader)\n",
    "    for im_1, im_2 in train_bar:\n",
    "        im_1, im_2 = im_1.cuda(non_blocking=True), im_2.cuda(non_blocking=True)\n",
    "\n",
    "        loss = net(im_1, im_2)\n",
    "        \n",
    "        train_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        train_optimizer.step()\n",
    "\n",
    "        #write to batch writer\n",
    "        #make batch count static\n",
    "        global batch_count\n",
    "        batch_writer.add_scalar('Loss/train_batch', loss, batch_count)\n",
    "        batch_count += 1\n",
    "        ########\n",
    "\n",
    "        total_num += data_loader.batch_size\n",
    "        total_loss += loss.item() * data_loader.batch_size\n",
    "        train_bar.set_description('Train Epoch: [{}/{}], lr: {:.6f}, Loss: {:.4f}'.format(epoch, epochs, optimizer.param_groups[0]['lr'], total_loss / total_num))\n",
    "\n",
    "    return total_loss / total_num\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "ConvNet\n",
      "ModuleList(\n",
      "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): Dropout(p=0.3, inplace=False)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): ReLU()\n",
      "  (8): Dropout(p=0.3, inplace=False)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (12): ReLU()\n",
      "  (13): Dropout(p=0.3, inplace=False)\n",
      "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "ConvNet\n",
      "ModuleList(\n",
      "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): Dropout(p=0.3, inplace=False)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): ReLU()\n",
      "  (8): Dropout(p=0.3, inplace=False)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (12): ReLU()\n",
      "  (13): Dropout(p=0.3, inplace=False)\n",
      "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "-----------------------------------------------------------\n",
      "ModelBase(\n",
      "  (conv): convNet(\n",
      "    (net): ModuleList(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Dropout(p=0.3, inplace=False)\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (7): ReLU()\n",
      "      (8): Dropout(p=0.3, inplace=False)\n",
      "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (12): ReLU()\n",
      "      (13): Dropout(p=0.3, inplace=False)\n",
      "      (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = ModelMoCo(\n",
    "        dim=moco_dim,\n",
    "        K=moco_k,\n",
    "        m=moco_m,\n",
    "        T=moco_t,\n",
    "\n",
    "        bn_splits=bn_splits,\n",
    "        symmetric=moco_loss_symmetric,\n",
    "    ).to(device)\n",
    "print(model.encoder_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging\n",
    "results = {'train_loss': []}\n",
    "#if results_dir not exists, then create one\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "#initialize summary writer in run directory in results_dir\n",
    "writer = SummaryWriter(f'{results_dir}/run/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: [1/200], lr: 0.059996, Loss: 15.9256: 100%|██████████| 97/97 [00:09<00:00,  9.92it/s]\n",
      "Train Epoch: [2/200], lr: 0.059985, Loss: 16.1166: 100%|██████████| 97/97 [00:08<00:00, 12.09it/s]\n",
      "Train Epoch: [3/200], lr: 0.059967, Loss: 16.1335: 100%|██████████| 97/97 [00:08<00:00, 11.94it/s]\n",
      "Train Epoch: [4/200], lr: 0.059941, Loss: 16.1301: 100%|██████████| 97/97 [00:08<00:00, 11.74it/s]\n",
      "Train Epoch: [5/200], lr: 0.059908, Loss: 16.1248: 100%|██████████| 97/97 [00:08<00:00, 11.71it/s]\n",
      "Train Epoch: [6/200], lr: 0.059867, Loss: 16.1305: 100%|██████████| 97/97 [00:08<00:00, 11.27it/s]\n",
      "Train Epoch: [7/200], lr: 0.059819, Loss: 16.1231: 100%|██████████| 97/97 [00:08<00:00, 11.03it/s]\n",
      "Train Epoch: [8/200], lr: 0.059763, Loss: 16.1269: 100%|██████████| 97/97 [00:08<00:00, 11.77it/s]\n",
      "Train Epoch: [9/200], lr: 0.059701, Loss: 16.1218: 100%|██████████| 97/97 [00:08<00:00, 11.62it/s]\n",
      "Train Epoch: [10/200], lr: 0.059631, Loss: 16.0959: 100%|██████████| 97/97 [00:08<00:00, 11.83it/s]\n",
      "Train Epoch: [11/200], lr: 0.059553, Loss: 16.1164: 100%|██████████| 97/97 [00:08<00:00, 11.33it/s]\n",
      "Train Epoch: [12/200], lr: 0.059469, Loss: 16.1210: 100%|██████████| 97/97 [00:07<00:00, 12.27it/s]\n",
      "Train Epoch: [13/200], lr: 0.059377, Loss: 16.1286: 100%|██████████| 97/97 [00:08<00:00, 11.71it/s]\n",
      "Train Epoch: [14/200], lr: 0.059278, Loss: 16.1207: 100%|██████████| 97/97 [00:08<00:00, 11.81it/s]\n",
      "Train Epoch: [15/200], lr: 0.059171, Loss: 16.1335: 100%|██████████| 97/97 [00:07<00:00, 12.26it/s]\n",
      "Train Epoch: [16/200], lr: 0.059057, Loss: 16.1061: 100%|██████████| 97/97 [00:08<00:00, 11.64it/s]\n",
      "Train Epoch: [17/200], lr: 0.058937, Loss: 16.1286: 100%|██████████| 97/97 [00:08<00:00, 11.85it/s]\n",
      "Train Epoch: [18/200], lr: 0.058809, Loss: 16.1103: 100%|██████████| 97/97 [00:08<00:00, 12.11it/s]\n",
      "Train Epoch: [19/200], lr: 0.058674, Loss: 16.1330: 100%|██████████| 97/97 [00:08<00:00, 11.95it/s]\n",
      "Train Epoch: [20/200], lr: 0.058532, Loss: 16.1265: 100%|██████████| 97/97 [00:08<00:00, 11.88it/s]\n",
      "Train Epoch: [21/200], lr: 0.058383, Loss: 16.1321: 100%|██████████| 97/97 [00:08<00:00, 11.96it/s]\n",
      "Train Epoch: [22/200], lr: 0.058226, Loss: 16.1224: 100%|██████████| 97/97 [00:08<00:00, 11.80it/s]\n",
      "Train Epoch: [23/200], lr: 0.058063, Loss: 16.1279: 100%|██████████| 97/97 [00:08<00:00, 11.77it/s]\n",
      "Train Epoch: [24/200], lr: 0.057893, Loss: 16.0943: 100%|██████████| 97/97 [00:08<00:00, 11.47it/s]\n",
      "Train Epoch: [25/200], lr: 0.057716, Loss: 16.1262: 100%|██████████| 97/97 [00:08<00:00, 12.03it/s]\n",
      "Train Epoch: [26/200], lr: 0.057533, Loss: 16.1159: 100%|██████████| 97/97 [00:08<00:00, 11.73it/s]\n",
      "Train Epoch: [27/200], lr: 0.057342, Loss: 16.1069: 100%|██████████| 97/97 [00:08<00:00, 11.90it/s]\n",
      "Train Epoch: [28/200], lr: 0.057145, Loss: 16.1050: 100%|██████████| 97/97 [00:07<00:00, 12.15it/s]\n",
      "Train Epoch: [29/200], lr: 0.056941, Loss: 16.1242: 100%|██████████| 97/97 [00:07<00:00, 12.24it/s]\n",
      "Train Epoch: [30/200], lr: 0.056730, Loss: 16.1277: 100%|██████████| 97/97 [00:08<00:00, 11.20it/s]\n",
      "Train Epoch: [31/200], lr: 0.056513, Loss: 16.1282: 100%|██████████| 97/97 [00:08<00:00, 12.01it/s]\n",
      "Train Epoch: [32/200], lr: 0.056289, Loss: 16.1263: 100%|██████████| 97/97 [00:08<00:00, 11.79it/s]\n",
      "Train Epoch: [33/200], lr: 0.056059, Loss: 16.1133: 100%|██████████| 97/97 [00:07<00:00, 12.22it/s]\n",
      "Train Epoch: [34/200], lr: 0.055822, Loss: 16.1174: 100%|██████████| 97/97 [00:08<00:00, 11.51it/s]\n",
      "Train Epoch: [35/200], lr: 0.055579, Loss: 16.1355: 100%|██████████| 97/97 [00:08<00:00, 11.47it/s]\n",
      "Train Epoch: [36/200], lr: 0.055330, Loss: 16.1242: 100%|██████████| 97/97 [00:08<00:00, 11.66it/s]\n",
      "Train Epoch: [37/200], lr: 0.055074, Loss: 16.1477: 100%|██████████| 97/97 [00:08<00:00, 11.77it/s]\n",
      "Train Epoch: [38/200], lr: 0.054812, Loss: 16.1188: 100%|██████████| 97/97 [00:08<00:00, 11.87it/s]\n",
      "Train Epoch: [39/200], lr: 0.054544, Loss: 16.1314: 100%|██████████| 97/97 [00:08<00:00, 12.03it/s]\n",
      "Train Epoch: [40/200], lr: 0.054271, Loss: 16.1443: 100%|██████████| 97/97 [00:07<00:00, 12.40it/s]\n",
      "Train Epoch: [41/200], lr: 0.053991, Loss: 16.1504: 100%|██████████| 97/97 [00:08<00:00, 11.56it/s]\n",
      "Train Epoch: [42/200], lr: 0.053705, Loss: 16.1344: 100%|██████████| 97/97 [00:08<00:00, 11.91it/s]\n",
      "Train Epoch: [43/200], lr: 0.053413, Loss: 16.1113: 100%|██████████| 97/97 [00:08<00:00, 12.07it/s]\n",
      "Train Epoch: [44/200], lr: 0.053115, Loss: 16.1241: 100%|██████████| 97/97 [00:08<00:00, 11.78it/s]\n",
      "Train Epoch: [45/200], lr: 0.052812, Loss: 16.0991: 100%|██████████| 97/97 [00:07<00:00, 12.25it/s]\n",
      "Train Epoch: [46/200], lr: 0.052503, Loss: 16.0926: 100%|██████████| 97/97 [00:08<00:00, 11.90it/s]\n",
      "Train Epoch: [47/200], lr: 0.052189, Loss: 16.1018: 100%|██████████| 97/97 [00:08<00:00, 11.55it/s]\n",
      "Train Epoch: [48/200], lr: 0.051869, Loss: 16.1256: 100%|██████████| 97/97 [00:08<00:00, 11.66it/s]\n",
      "Train Epoch: [49/200], lr: 0.051544, Loss: 16.1039: 100%|██████████| 97/97 [00:08<00:00, 12.04it/s]\n",
      "Train Epoch: [50/200], lr: 0.051213, Loss: 16.1165: 100%|██████████| 97/97 [00:07<00:00, 12.14it/s]\n",
      "Train Epoch: [51/200], lr: 0.050877, Loss: 16.0897: 100%|██████████| 97/97 [00:08<00:00, 12.07it/s]\n",
      "Train Epoch: [52/200], lr: 0.050536, Loss: 16.1178: 100%|██████████| 97/97 [00:08<00:00, 11.77it/s]\n",
      "Train Epoch: [53/200], lr: 0.050190, Loss: 16.1190: 100%|██████████| 97/97 [00:08<00:00, 11.76it/s]\n",
      "Train Epoch: [54/200], lr: 0.049839, Loss: 16.1208: 100%|██████████| 97/97 [00:08<00:00, 12.09it/s]\n",
      "Train Epoch: [55/200], lr: 0.049483, Loss: 16.1043: 100%|██████████| 97/97 [00:08<00:00, 11.99it/s]\n",
      "Train Epoch: [56/200], lr: 0.049123, Loss: 16.1338: 100%|██████████| 97/97 [00:08<00:00, 12.01it/s]\n",
      "Train Epoch: [57/200], lr: 0.048757, Loss: 16.1344: 100%|██████████| 97/97 [00:07<00:00, 12.26it/s]\n",
      "Train Epoch: [58/200], lr: 0.048387, Loss: 16.1461: 100%|██████████| 97/97 [00:08<00:00, 11.10it/s]\n",
      "Train Epoch: [59/200], lr: 0.048013, Loss: 16.1304: 100%|██████████| 97/97 [00:08<00:00, 11.88it/s]\n",
      "Train Epoch: [60/200], lr: 0.047634, Loss: 16.1169: 100%|██████████| 97/97 [00:08<00:00, 11.80it/s]\n",
      "Train Epoch: [61/200], lr: 0.047250, Loss: 16.1268: 100%|██████████| 97/97 [00:08<00:00, 11.84it/s]\n",
      "Train Epoch: [62/200], lr: 0.046863, Loss: 16.1284: 100%|██████████| 97/97 [00:08<00:00, 11.60it/s]\n",
      "Train Epoch: [63/200], lr: 0.046471, Loss: 16.1313: 100%|██████████| 97/97 [00:08<00:00, 11.09it/s]\n",
      "Train Epoch: [64/200], lr: 0.046075, Loss: 16.1256: 100%|██████████| 97/97 [00:08<00:00, 11.82it/s]\n",
      "Train Epoch: [65/200], lr: 0.045675, Loss: 16.1188: 100%|██████████| 97/97 [00:08<00:00, 11.69it/s]\n",
      "Train Epoch: [66/200], lr: 0.045271, Loss: 16.1253: 100%|██████████| 97/97 [00:07<00:00, 12.25it/s]\n",
      "Train Epoch: [67/200], lr: 0.044864, Loss: 16.1398: 100%|██████████| 97/97 [00:08<00:00, 11.65it/s]\n",
      "Train Epoch: [68/200], lr: 0.044453, Loss: 16.1227: 100%|██████████| 97/97 [00:08<00:00, 12.08it/s]\n",
      "Train Epoch: [69/200], lr: 0.044038, Loss: 16.1185: 100%|██████████| 97/97 [00:08<00:00, 11.70it/s]\n",
      "Train Epoch: [70/200], lr: 0.043620, Loss: 16.1380: 100%|██████████| 97/97 [00:08<00:00, 11.92it/s]\n",
      "Train Epoch: [71/200], lr: 0.043198, Loss: 16.1203: 100%|██████████| 97/97 [00:07<00:00, 12.23it/s]\n",
      "Train Epoch: [72/200], lr: 0.042773, Loss: 16.1172: 100%|██████████| 97/97 [00:08<00:00, 12.08it/s]\n",
      "Train Epoch: [73/200], lr: 0.042345, Loss: 16.0978: 100%|██████████| 97/97 [00:08<00:00, 12.09it/s]\n",
      "Train Epoch: [74/200], lr: 0.041914, Loss: 16.1306: 100%|██████████| 97/97 [00:08<00:00, 11.98it/s]\n",
      "Train Epoch: [75/200], lr: 0.041481, Loss: 16.1170: 100%|██████████| 97/97 [00:08<00:00, 11.75it/s]\n",
      "Train Epoch: [76/200], lr: 0.041044, Loss: 16.1179: 100%|██████████| 97/97 [00:08<00:00, 12.03it/s]\n",
      "Train Epoch: [77/200], lr: 0.040604, Loss: 16.1266: 100%|██████████| 97/97 [00:08<00:00, 12.07it/s]\n",
      "Train Epoch: [78/200], lr: 0.040162, Loss: 16.1261: 100%|██████████| 97/97 [00:08<00:00, 11.85it/s]\n",
      "Train Epoch: [79/200], lr: 0.039718, Loss: 16.1295: 100%|██████████| 97/97 [00:08<00:00, 11.52it/s]\n",
      "Train Epoch: [80/200], lr: 0.039271, Loss: 16.1242: 100%|██████████| 97/97 [00:08<00:00, 12.11it/s]\n",
      "Train Epoch: [81/200], lr: 0.038821, Loss: 16.1098: 100%|██████████| 97/97 [00:08<00:00, 11.89it/s]\n",
      "Train Epoch: [82/200], lr: 0.038370, Loss: 16.1188: 100%|██████████| 97/97 [00:08<00:00, 11.89it/s]\n",
      "Train Epoch: [83/200], lr: 0.037916, Loss: 16.1426: 100%|██████████| 97/97 [00:07<00:00, 12.50it/s]\n",
      "Train Epoch: [84/200], lr: 0.037461, Loss: 16.1180: 100%|██████████| 97/97 [00:07<00:00, 12.13it/s]\n",
      "Train Epoch: [85/200], lr: 0.037003, Loss: 16.1273: 100%|██████████| 97/97 [00:08<00:00, 11.91it/s]\n",
      "Train Epoch: [86/200], lr: 0.036544, Loss: 16.1067: 100%|██████████| 97/97 [00:08<00:00, 11.94it/s]\n",
      "Train Epoch: [87/200], lr: 0.036084, Loss: 16.1367: 100%|██████████| 97/97 [00:08<00:00, 11.95it/s]\n",
      "Train Epoch: [88/200], lr: 0.035621, Loss: 16.1176: 100%|██████████| 97/97 [00:08<00:00, 11.27it/s]\n",
      "Train Epoch: [89/200], lr: 0.035158, Loss: 16.1180: 100%|██████████| 97/97 [00:08<00:00, 11.99it/s]\n",
      "Train Epoch: [90/200], lr: 0.034693, Loss: 16.1100: 100%|██████████| 97/97 [00:08<00:00, 11.69it/s]\n",
      "Train Epoch: [91/200], lr: 0.034227, Loss: 16.1403: 100%|██████████| 97/97 [00:07<00:00, 12.23it/s]\n",
      "Train Epoch: [92/200], lr: 0.033760, Loss: 16.1412: 100%|██████████| 97/97 [00:08<00:00, 11.99it/s]\n",
      "Train Epoch: [93/200], lr: 0.033292, Loss: 16.1257: 100%|██████████| 97/97 [00:08<00:00, 11.75it/s]\n",
      "Train Epoch: [94/200], lr: 0.032823, Loss: 16.1152: 100%|██████████| 97/97 [00:08<00:00, 12.03it/s]\n",
      "Train Epoch: [95/200], lr: 0.032354, Loss: 16.1171: 100%|██████████| 97/97 [00:08<00:00, 11.29it/s]\n",
      "Train Epoch: [96/200], lr: 0.031884, Loss: 16.1077: 100%|██████████| 97/97 [00:08<00:00, 11.92it/s]\n",
      "Train Epoch: [97/200], lr: 0.031413, Loss: 16.1391: 100%|██████████| 97/97 [00:08<00:00, 12.06it/s]\n",
      "Train Epoch: [98/200], lr: 0.030942, Loss: 16.0991: 100%|██████████| 97/97 [00:08<00:00, 11.56it/s]\n",
      "Train Epoch: [99/200], lr: 0.030471, Loss: 16.1359: 100%|██████████| 97/97 [00:08<00:00, 11.56it/s]\n",
      "Train Epoch: [100/200], lr: 0.030000, Loss: 16.1208: 100%|██████████| 97/97 [00:08<00:00, 11.97it/s]\n",
      "Train Epoch: [101/200], lr: 0.029529, Loss: 16.1284: 100%|██████████| 97/97 [00:08<00:00, 11.88it/s]\n",
      "Train Epoch: [102/200], lr: 0.029058, Loss: 16.1188: 100%|██████████| 97/97 [00:08<00:00, 11.39it/s]\n",
      "Train Epoch: [103/200], lr: 0.028587, Loss: 16.1248: 100%|██████████| 97/97 [00:08<00:00, 11.64it/s]\n",
      "Train Epoch: [104/200], lr: 0.028116, Loss: 16.1244: 100%|██████████| 97/97 [00:08<00:00, 11.62it/s]\n",
      "Train Epoch: [105/200], lr: 0.027646, Loss: 16.1130: 100%|██████████| 97/97 [00:07<00:00, 12.26it/s]\n",
      "Train Epoch: [106/200], lr: 0.027177, Loss: 16.1042: 100%|██████████| 97/97 [00:08<00:00, 12.09it/s]\n",
      "Train Epoch: [107/200], lr: 0.026708, Loss: 16.1414: 100%|██████████| 97/97 [00:08<00:00, 11.12it/s]\n",
      "Train Epoch: [108/200], lr: 0.026240, Loss: 16.1112: 100%|██████████| 97/97 [00:08<00:00, 11.60it/s]\n",
      "Train Epoch: [109/200], lr: 0.025773, Loss: 16.1170: 100%|██████████| 97/97 [00:08<00:00, 11.83it/s]\n",
      "Train Epoch: [110/200], lr: 0.025307, Loss: 16.1269: 100%|██████████| 97/97 [00:08<00:00, 11.36it/s]\n",
      "Train Epoch: [111/200], lr: 0.024842, Loss: 16.1162: 100%|██████████| 97/97 [00:08<00:00, 11.95it/s]\n",
      "Train Epoch: [112/200], lr: 0.024379, Loss: 16.1269: 100%|██████████| 97/97 [00:08<00:00, 11.95it/s]\n",
      "Train Epoch: [113/200], lr: 0.023916, Loss: 16.0993: 100%|██████████| 97/97 [00:07<00:00, 12.14it/s]\n",
      "Train Epoch: [114/200], lr: 0.023456, Loss: 16.1128: 100%|██████████| 97/97 [00:08<00:00, 11.80it/s]\n",
      "Train Epoch: [115/200], lr: 0.022997, Loss: 16.1358: 100%|██████████| 97/97 [00:08<00:00, 11.46it/s]\n",
      "Train Epoch: [116/200], lr: 0.022539, Loss: 16.1280: 100%|██████████| 97/97 [00:07<00:00, 12.15it/s]\n",
      "Train Epoch: [117/200], lr: 0.022084, Loss: 16.1144: 100%|██████████| 97/97 [00:08<00:00, 11.90it/s]\n",
      "Train Epoch: [118/200], lr: 0.021630, Loss: 16.1335: 100%|██████████| 97/97 [00:08<00:00, 12.12it/s]\n",
      "Train Epoch: [119/200], lr: 0.021179, Loss: 16.1388: 100%|██████████| 97/97 [00:08<00:00, 12.02it/s]\n",
      "Train Epoch: [120/200], lr: 0.020729, Loss: 16.1042: 100%|██████████| 97/97 [00:08<00:00, 11.65it/s]\n",
      "Train Epoch: [121/200], lr: 0.020282, Loss: 16.1204: 100%|██████████| 97/97 [00:08<00:00, 11.71it/s]\n",
      "Train Epoch: [122/200], lr: 0.019838, Loss: 16.1446: 100%|██████████| 97/97 [00:08<00:00, 11.61it/s]\n",
      "Train Epoch: [123/200], lr: 0.019396, Loss: 16.1445: 100%|██████████| 97/97 [00:08<00:00, 11.83it/s]\n",
      "Train Epoch: [124/200], lr: 0.018956, Loss: 16.1205: 100%|██████████| 97/97 [00:08<00:00, 11.30it/s]\n",
      "Train Epoch: [125/200], lr: 0.018519, Loss: 16.1367: 100%|██████████| 97/97 [00:07<00:00, 12.26it/s]\n",
      "Train Epoch: [126/200], lr: 0.018086, Loss: 16.1360: 100%|██████████| 97/97 [00:08<00:00, 11.86it/s]\n",
      "Train Epoch: [127/200], lr: 0.017655, Loss: 16.1246: 100%|██████████| 97/97 [00:08<00:00, 12.03it/s]\n",
      "Train Epoch: [128/200], lr: 0.017227, Loss: 16.1234: 100%|██████████| 97/97 [00:07<00:00, 12.14it/s]\n",
      "Train Epoch: [129/200], lr: 0.016802, Loss: 16.1661: 100%|██████████| 97/97 [00:08<00:00, 11.67it/s]\n",
      "Train Epoch: [130/200], lr: 0.016380, Loss: 16.1097: 100%|██████████| 97/97 [00:08<00:00, 12.12it/s]\n",
      "Train Epoch: [131/200], lr: 0.015962, Loss: 16.1142: 100%|██████████| 97/97 [00:07<00:00, 12.43it/s]\n",
      "Train Epoch: [132/200], lr: 0.015547, Loss: 16.1413: 100%|██████████| 97/97 [00:08<00:00, 12.08it/s]\n",
      "Train Epoch: [133/200], lr: 0.015136, Loss: 16.1189: 100%|██████████| 97/97 [00:08<00:00, 11.57it/s]\n",
      "Train Epoch: [134/200], lr: 0.014729, Loss: 16.1165: 100%|██████████| 97/97 [00:07<00:00, 12.36it/s]\n",
      "Train Epoch: [135/200], lr: 0.014325, Loss: 16.1192: 100%|██████████| 97/97 [00:07<00:00, 12.30it/s]\n",
      "Train Epoch: [136/200], lr: 0.013925, Loss: 16.1141: 100%|██████████| 97/97 [00:08<00:00, 12.12it/s]\n",
      "Train Epoch: [137/200], lr: 0.013529, Loss: 16.1410: 100%|██████████| 97/97 [00:08<00:00, 12.09it/s]\n",
      "Train Epoch: [138/200], lr: 0.013137, Loss: 16.1436: 100%|██████████| 97/97 [00:08<00:00, 11.55it/s]\n",
      "Train Epoch: [139/200], lr: 0.012750, Loss: 16.1004: 100%|██████████| 97/97 [00:08<00:00, 11.83it/s]\n",
      "Train Epoch: [140/200], lr: 0.012366, Loss: 16.1112: 100%|██████████| 97/97 [00:08<00:00, 11.80it/s]\n",
      "Train Epoch: [141/200], lr: 0.011987, Loss: 16.1485: 100%|██████████| 97/97 [00:08<00:00, 11.87it/s]\n",
      "Train Epoch: [142/200], lr: 0.011613, Loss: 16.1181: 100%|██████████| 97/97 [00:08<00:00, 11.01it/s]\n",
      "Train Epoch: [143/200], lr: 0.011243, Loss: 16.1040: 100%|██████████| 97/97 [00:08<00:00, 11.92it/s]\n",
      "Train Epoch: [144/200], lr: 0.010877, Loss: 16.1238: 100%|██████████| 97/97 [00:08<00:00, 12.01it/s]\n",
      "Train Epoch: [145/200], lr: 0.010517, Loss: 16.1163: 100%|██████████| 97/97 [00:07<00:00, 12.37it/s]\n",
      "Train Epoch: [146/200], lr: 0.010161, Loss: 16.1426: 100%|██████████| 97/97 [00:08<00:00, 11.09it/s]\n",
      "Train Epoch: [147/200], lr: 0.009810, Loss: 16.1232: 100%|██████████| 97/97 [00:08<00:00, 11.54it/s]\n",
      "Train Epoch: [148/200], lr: 0.009464, Loss: 16.1318: 100%|██████████| 97/97 [00:09<00:00, 10.78it/s]\n",
      "Train Epoch: [149/200], lr: 0.009123, Loss: 16.1155: 100%|██████████| 97/97 [00:08<00:00, 11.58it/s]\n",
      "Train Epoch: [150/200], lr: 0.008787, Loss: 16.1107: 100%|██████████| 97/97 [00:07<00:00, 12.17it/s]\n",
      "Train Epoch: [151/200], lr: 0.008456, Loss: 16.1480: 100%|██████████| 97/97 [00:07<00:00, 12.16it/s]\n",
      "Train Epoch: [152/200], lr: 0.008131, Loss: 16.1231: 100%|██████████| 97/97 [00:08<00:00, 11.63it/s]\n",
      "Train Epoch: [153/200], lr: 0.007811, Loss: 16.1285: 100%|██████████| 97/97 [00:08<00:00, 11.88it/s]\n",
      "Train Epoch: [154/200], lr: 0.007497, Loss: 16.1292: 100%|██████████| 97/97 [00:07<00:00, 12.22it/s]\n",
      "Train Epoch: [155/200], lr: 0.007188, Loss: 16.1095: 100%|██████████| 97/97 [00:08<00:00, 12.05it/s]\n",
      "Train Epoch: [156/200], lr: 0.006885, Loss: 16.1187: 100%|██████████| 97/97 [00:08<00:00, 11.45it/s]\n",
      "Train Epoch: [157/200], lr: 0.006587, Loss: 16.1274: 100%|██████████| 97/97 [00:08<00:00, 11.82it/s]\n",
      "Train Epoch: [158/200], lr: 0.006295, Loss: 16.1429: 100%|██████████| 97/97 [00:08<00:00, 11.77it/s]\n",
      "Train Epoch: [159/200], lr: 0.006009, Loss: 16.1219: 100%|██████████| 97/97 [00:07<00:00, 12.15it/s]\n",
      "Train Epoch: [160/200], lr: 0.005729, Loss: 16.1215: 100%|██████████| 97/97 [00:08<00:00, 11.90it/s]\n",
      "Train Epoch: [161/200], lr: 0.005456, Loss: 16.1235: 100%|██████████| 97/97 [00:08<00:00, 11.90it/s]\n",
      "Train Epoch: [162/200], lr: 0.005188, Loss: 16.1066: 100%|██████████| 97/97 [00:08<00:00, 11.78it/s]\n",
      "Train Epoch: [163/200], lr: 0.004926, Loss: 16.1408: 100%|██████████| 97/97 [00:08<00:00, 11.65it/s]\n",
      "Train Epoch: [164/200], lr: 0.004670, Loss: 16.1351: 100%|██████████| 97/97 [00:08<00:00, 12.03it/s]\n",
      "Train Epoch: [165/200], lr: 0.004421, Loss: 16.1396: 100%|██████████| 97/97 [00:08<00:00, 11.44it/s]\n",
      "Train Epoch: [166/200], lr: 0.004178, Loss: 16.1338: 100%|██████████| 97/97 [00:08<00:00, 11.74it/s]\n",
      "Train Epoch: [167/200], lr: 0.003941, Loss: 16.1294: 100%|██████████| 97/97 [00:07<00:00, 12.14it/s]\n",
      "Train Epoch: [168/200], lr: 0.003711, Loss: 16.1129: 100%|██████████| 97/97 [00:08<00:00, 11.82it/s]\n",
      "Train Epoch: [169/200], lr: 0.003487, Loss: 16.1430: 100%|██████████| 97/97 [00:08<00:00, 11.70it/s]\n",
      "Train Epoch: [170/200], lr: 0.003270, Loss: 16.1336: 100%|██████████| 97/97 [00:08<00:00, 11.90it/s]\n",
      "Train Epoch: [171/200], lr: 0.003059, Loss: 16.1221: 100%|██████████| 97/97 [00:08<00:00, 11.62it/s]\n",
      "Train Epoch: [172/200], lr: 0.002855, Loss: 16.1551: 100%|██████████| 97/97 [00:08<00:00, 11.87it/s]\n",
      "Train Epoch: [173/200], lr: 0.002658, Loss: 16.1216: 100%|██████████| 97/97 [00:08<00:00, 11.26it/s]\n",
      "Train Epoch: [174/200], lr: 0.002467, Loss: 16.1019: 100%|██████████| 97/97 [00:07<00:00, 12.14it/s]\n",
      "Train Epoch: [175/200], lr: 0.002284, Loss: 16.1156: 100%|██████████| 97/97 [00:08<00:00, 11.51it/s]\n",
      "Train Epoch: [176/200], lr: 0.002107, Loss: 16.1286: 100%|██████████| 97/97 [00:08<00:00, 11.58it/s]\n",
      "Train Epoch: [177/200], lr: 0.001937, Loss: 16.1273: 100%|██████████| 97/97 [00:08<00:00, 11.87it/s]\n",
      "Train Epoch: [178/200], lr: 0.001774, Loss: 16.1077: 100%|██████████| 97/97 [00:07<00:00, 12.21it/s]\n",
      "Train Epoch: [179/200], lr: 0.001617, Loss: 16.1244: 100%|██████████| 97/97 [00:08<00:00, 11.82it/s]\n",
      "Train Epoch: [180/200], lr: 0.001468, Loss: 16.1384: 100%|██████████| 97/97 [00:08<00:00, 11.78it/s]\n",
      "Train Epoch: [181/200], lr: 0.001326, Loss: 16.1268: 100%|██████████| 97/97 [00:07<00:00, 12.36it/s]\n",
      "Train Epoch: [182/200], lr: 0.001191, Loss: 16.1048: 100%|██████████| 97/97 [00:08<00:00, 12.05it/s]\n",
      "Train Epoch: [183/200], lr: 0.001063, Loss: 16.1330: 100%|██████████| 97/97 [00:08<00:00, 11.53it/s]\n",
      "Train Epoch: [184/200], lr: 0.000943, Loss: 16.1169: 100%|██████████| 97/97 [00:08<00:00, 12.05it/s]\n",
      "Train Epoch: [185/200], lr: 0.000829, Loss: 16.1300: 100%|██████████| 97/97 [00:07<00:00, 12.36it/s]\n",
      "Train Epoch: [186/200], lr: 0.000722, Loss: 16.1127: 100%|██████████| 97/97 [00:07<00:00, 12.30it/s]\n",
      "Train Epoch: [187/200], lr: 0.000623, Loss: 16.1107: 100%|██████████| 97/97 [00:08<00:00, 11.68it/s]\n",
      "Train Epoch: [188/200], lr: 0.000531, Loss: 16.1326: 100%|██████████| 97/97 [00:07<00:00, 12.22it/s]\n",
      "Train Epoch: [189/200], lr: 0.000447, Loss: 16.1147: 100%|██████████| 97/97 [00:08<00:00, 11.42it/s]\n",
      "Train Epoch: [190/200], lr: 0.000369, Loss: 16.1167: 100%|██████████| 97/97 [00:08<00:00, 11.78it/s]\n",
      "Train Epoch: [191/200], lr: 0.000299, Loss: 16.1273: 100%|██████████| 97/97 [00:08<00:00, 11.40it/s]\n",
      "Train Epoch: [192/200], lr: 0.000237, Loss: 16.1073: 100%|██████████| 97/97 [00:08<00:00, 11.71it/s]\n",
      "Train Epoch: [193/200], lr: 0.000181, Loss: 16.1214: 100%|██████████| 97/97 [00:08<00:00, 12.03it/s]\n",
      "Train Epoch: [194/200], lr: 0.000133, Loss: 16.1320: 100%|██████████| 97/97 [00:08<00:00, 11.62it/s]\n",
      "Train Epoch: [195/200], lr: 0.000092, Loss: 16.1160: 100%|██████████| 97/97 [00:08<00:00, 11.62it/s]\n",
      "Train Epoch: [196/200], lr: 0.000059, Loss: 16.1111: 100%|██████████| 97/97 [00:08<00:00, 11.42it/s]\n",
      "Train Epoch: [197/200], lr: 0.000033, Loss: 16.1409: 100%|██████████| 97/97 [00:08<00:00, 11.50it/s]\n",
      "Train Epoch: [198/200], lr: 0.000015, Loss: 16.1241: 100%|██████████| 97/97 [00:08<00:00, 11.37it/s]\n",
      "Train Epoch: [199/200], lr: 0.000004, Loss: 16.1416: 100%|██████████| 97/97 [00:08<00:00, 11.96it/s]\n",
      "Train Epoch: [200/200], lr: 0.000000, Loss: 16.1013: 100%|██████████| 97/97 [00:08<00:00, 11.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "epoch_start = 1\n",
    "for epoch in range(epoch_start, epochs + 1):\n",
    "    \n",
    "    train_loss = train(model, train_loader, optimizer, epoch)\n",
    "    results['train_loss'].append(train_loss)\n",
    "    writer.add_scalar('Loss/train_epoch', train_loss, epoch)\n",
    "    #if last epoch save model\n",
    "    if epoch == epochs:\n",
    "        torch.save(model.state_dict(), moco_pretrained_dir+'.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #write a function to load the trained moco model, \n",
    "# def load_moco_model(path = moco_pretrained_dir):\n",
    "#     model = ModelMoCo(\n",
    "#         dim=moco_dim,\n",
    "#         K=moco_k,\n",
    "#         m=moco_m,\n",
    "#         T=moco_t,\n",
    "\n",
    "#         bn_splits=bn_splits,\n",
    "#         symmetric=moco_loss_symmetric,\n",
    "#     )\n",
    "#     model.load_state_dict(torch.load(path))\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load saved moco model but return only the encoder_q\n",
    "def load_moco_model(path = moco_pretrained_dir):\n",
    "    model = ModelMoCo(\n",
    "        dim=moco_dim,\n",
    "        K=moco_k,\n",
    "        m=moco_m,\n",
    "        T=moco_t,\n",
    "\n",
    "        bn_splits=bn_splits,\n",
    "        symmetric=moco_loss_symmetric,\n",
    "    )\n",
    "    model.load_state_dict(torch.load(path+'.pth'))\n",
    "    return model.encoder_q\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Learned Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will test using the standard Linear classification Protocol\n",
    "#the Linear classification Protocol is : as unsupervised representations are learned, use a linear and logistic layers and retrain with 10-50% of supervised training data\n",
    "\n",
    "#we have 2 test tasks \n",
    "#TASK 1: Binary Classifier\n",
    "#TASk 2: 5-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we define a classifier class, that takes in number of classes\n",
    "#it will first make a copy of the ModelMoCo class, load the pretrained weights, make the weights non-trainable\n",
    "#then we will add a linear layer and a logistic layer to the model to match the number of classes\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.moco = load_moco_model()\n",
    "        #freeze the weights\n",
    "        for param in self.moco.parameters():\n",
    "            param.requires_grad = False\n",
    "        #add a linear layer and a softmax layer\n",
    "        self.linear = nn.Linear(moco_dim, num_classes)\n",
    "        #add logistic layer\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        x = self.moco(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "ConvNet\n",
      "ModuleList(\n",
      "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): Dropout(p=0.3, inplace=False)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): ReLU()\n",
      "  (8): Dropout(p=0.3, inplace=False)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (12): ReLU()\n",
      "  (13): Dropout(p=0.3, inplace=False)\n",
      "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "ConvNet\n",
      "ModuleList(\n",
      "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): Dropout(p=0.3, inplace=False)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): ReLU()\n",
      "  (8): Dropout(p=0.3, inplace=False)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (12): ReLU()\n",
      "  (13): Dropout(p=0.3, inplace=False)\n",
      "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "-----------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 30, 30]             864\n",
      "       BatchNorm2d-2           [-1, 32, 30, 30]              64\n",
      "              ReLU-3           [-1, 32, 30, 30]               0\n",
      "           Dropout-4           [-1, 32, 30, 30]               0\n",
      "         MaxPool2d-5           [-1, 32, 15, 15]               0\n",
      "            Conv2d-6           [-1, 64, 13, 13]          18,432\n",
      "       BatchNorm2d-7           [-1, 64, 13, 13]             128\n",
      "              ReLU-8           [-1, 64, 13, 13]               0\n",
      "           Dropout-9           [-1, 64, 13, 13]               0\n",
      "        MaxPool2d-10             [-1, 64, 6, 6]               0\n",
      "           Conv2d-11            [-1, 128, 4, 4]          73,728\n",
      "      BatchNorm2d-12            [-1, 128, 4, 4]             256\n",
      "             ReLU-13            [-1, 128, 4, 4]               0\n",
      "          Dropout-14            [-1, 128, 4, 4]               0\n",
      "        MaxPool2d-15            [-1, 128, 2, 2]               0\n",
      "          convNet-16            [-1, 128, 2, 2]               0\n",
      "          Flatten-17                  [-1, 512]               0\n",
      "           Linear-18                  [-1, 512]         262,656\n",
      "        ModelBase-19                  [-1, 512]               0\n",
      "           Linear-20                    [-1, 2]           1,026\n",
      "          Softmax-21                    [-1, 2]               0\n",
      "================================================================\n",
      "Total params: 357,154\n",
      "Trainable params: 1,026\n",
      "Non-trainable params: 356,128\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.36\n",
      "Params size (MB): 1.36\n",
      "Estimated Total Size (MB): 2.74\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#print summary of the model\n",
    "model = Classifier(2)\n",
    "summary(model.to(device), (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier(\n",
      "  (moco): ModelBase(\n",
      "    (conv): convNet(\n",
      "      (net): ModuleList(\n",
      "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.3, inplace=False)\n",
      "        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU()\n",
      "        (8): Dropout(p=0.3, inplace=False)\n",
      "        (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (12): ReLU()\n",
      "        (13): Dropout(p=0.3, inplace=False)\n",
      "        (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "    (flat): Flatten(start_dim=1, end_dim=-1)\n",
      "    (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "  )\n",
      "  (linear): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dataloader for supervised training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#define train and test loaders\n",
    "#get train loader only fraction_trainig_data\n",
    "#we load cifar10 dataset from torchvision\n",
    "train_data_supervised = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=test_transform)\n",
    "#take only fraction of training data : fraction_training_data \n",
    "train_data_supervised = torch.utils.data.Subset(train_data_supervised, indices = np.random.choice(len(train_data_supervised), int(fraction_training_data*len(train_data_supervised)), replace=False))\n",
    "\n",
    "#train dataloader\n",
    "train_loader_supervised = torch.utils.data.DataLoader(train_data_supervised, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supervised Training Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will have a supervised training loop on a model given by the classifier class\n",
    "def supervised_training(model,label_fun, model_save_path, epochs= super_epochs, lr):\n",
    "\n",
    "    #loss function\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    #optimizer, we will only train the linear and logistic layers, thus we will only pass the parameters of the linear and logistic layers, i.e only the trainable parameters\n",
    "    #pass only the parameters of last linear layer and softmax layer\n",
    "    optimizer = torch.optim.SGD(model.linear.parameters(), lr=super_lr)\n",
    "    #CosineAnnealingLR scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "\n",
    "\n",
    "\n",
    "    model.train()\n",
    "    #send model to device\n",
    "    model.to(device)\n",
    "    train_bar = tqdm(train_loader)\n",
    "    #loop for number of epochs\n",
    "    batch_counter = 0\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        total_correct = 0\n",
    "        total_items = 0\n",
    "        #loop for number of batches\n",
    "        for batch_idx, (data, target) in enumerate(train_loader_supervised):\n",
    "            #send data and target to device\n",
    "            data, target = data.to(device), target\n",
    "            #get binary target\n",
    "            target = label_fun(target)\n",
    "            #send to device\n",
    "            target = target.to(device)\n",
    "            #zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            #forward pass\n",
    "            output = model(data)\n",
    "            #calculate loss\n",
    "            loss = criterion(output, target)\n",
    "            #backward pass\n",
    "            loss.backward()\n",
    "            #update weights\n",
    "            optimizer.step()\n",
    "            #update epoch loss\n",
    "            epoch_loss += loss.item()\n",
    "            #get classification accuracy\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total = target.size(0)\n",
    "            correct = (predicted == target).sum().item()\n",
    "            total_correct += correct\n",
    "            total_items += total\n",
    "            #update progress bar\n",
    "            # train_bar.set_description(desc= f'epoch {epoch} loss={loss.item()} batch_id={batch_idx} Accuracy={100 * correct / total}')\n",
    "            #print\n",
    "            if batch_idx % 25 == 0:\n",
    "                print('Epoch : %d/%d, Batch : %d/%d, Loss : %.4f, Accuracy : %.4f'\n",
    "                    %(epoch+1, epochs, batch_idx+1, len(train_loader_supervised), loss.item(), 100 * correct / total))\n",
    "\n",
    "            #write to tensorboard\n",
    "            writer.add_scalar('Loss/batch_train_supervised_binary_classifier', loss.item(), batch_counter)\n",
    "            writer.add_scalar('Accuracy/batch_train_supervised_binary_classifier', 100 * correct / total, batch_counter)\n",
    "            batch_counter += 1\n",
    "\n",
    "        #update scheduler\n",
    "        scheduler.step()\n",
    "        #print epoch loss\n",
    "        print(\"epoch loss\",epoch_loss/len(train_loader))\n",
    "        #print epoch accuracy\n",
    "        print(\"epoch accuracy\",total_correct/total_items)\n",
    "        #write to tensorboard\n",
    "        writer.add_scalar('Loss/epoch_train_supervised_binary_classifier', epoch_loss/len(train_loader), epoch)\n",
    "        writer.add_scalar('Accuracy/epoch_train_supervised_binary_classifier', total_correct/total_items, epoch)\n",
    "        #if last epoch , then save the model\n",
    "        if epoch == epochs-1:\n",
    "            torch.save(model.state_dict(), model_save_path+'.pt')\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## TASK 0: CIFAR10 10-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define 10 class label\n",
    "def ten_class_label(ip):\n",
    "    return ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will call the supervised training function for 10 class classification\n",
    "#we will build the parameters for the function\n",
    "#model\n",
    "model = Classifier(10)\n",
    "model_save_path = moco_pretrained_dir + '_supervised_ten_class_classifier'\n",
    "#call the function\n",
    "model = supervised_training(model, ten_class_label, model_save_path, epochs= super_epochs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## TASK 1: Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will define binary label function that will map the input label: 0 to 9 to either 0 or 1\n",
    "#y = torch.tensor([1 if x in [2,3,4,5,6,7] else 0 for x in y])\n",
    "def binary_label(y):\n",
    "    y = torch.tensor([1 if x in [2,3,4,5,6,7] else 0 for x in y])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "ConvNet\n",
      "ModuleList(\n",
      "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): Dropout(p=0.3, inplace=False)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): ReLU()\n",
      "  (8): Dropout(p=0.3, inplace=False)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (12): ReLU()\n",
      "  (13): Dropout(p=0.3, inplace=False)\n",
      "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "ConvNet\n",
      "ModuleList(\n",
      "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): Dropout(p=0.3, inplace=False)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): ReLU()\n",
      "  (8): Dropout(p=0.3, inplace=False)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (12): ReLU()\n",
      "  (13): Dropout(p=0.3, inplace=False)\n",
      "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "-----------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1/10, Batch : 1/49, Loss : 0.7013, Accuracy : 50.7812\n",
      "Epoch : 1/10, Batch : 26/49, Loss : 0.6825, Accuracy : 58.3984\n",
      "epoch loss 0.345010670190005\n",
      "epoch accuracy 0.57452\n",
      "Epoch : 2/10, Batch : 1/49, Loss : 0.6617, Accuracy : 64.8438\n",
      "Epoch : 2/10, Batch : 26/49, Loss : 0.6462, Accuracy : 68.1641\n",
      "epoch loss 0.3322585550780149\n",
      "epoch accuracy 0.63704\n",
      "Epoch : 3/10, Batch : 1/49, Loss : 0.6443, Accuracy : 64.2578\n",
      "Epoch : 3/10, Batch : 26/49, Loss : 0.6408, Accuracy : 64.6484\n",
      "epoch loss 0.32388947735127716\n",
      "epoch accuracy 0.66048\n",
      "Epoch : 4/10, Batch : 1/49, Loss : 0.6489, Accuracy : 61.5234\n",
      "Epoch : 4/10, Batch : 26/49, Loss : 0.6198, Accuracy : 70.3125\n",
      "epoch loss 0.317789346286931\n",
      "epoch accuracy 0.67896\n",
      "Epoch : 5/10, Batch : 1/49, Loss : 0.6287, Accuracy : 67.1875\n",
      "Epoch : 5/10, Batch : 26/49, Loss : 0.6157, Accuracy : 69.9219\n",
      "epoch loss 0.3127829358749783\n",
      "epoch accuracy 0.69768\n",
      "Epoch : 6/10, Batch : 1/49, Loss : 0.6142, Accuracy : 69.5312\n",
      "Epoch : 6/10, Batch : 26/49, Loss : 0.6134, Accuracy : 70.7031\n",
      "epoch loss 0.3094721682292899\n",
      "epoch accuracy 0.70872\n",
      "Epoch : 7/10, Batch : 1/49, Loss : 0.6067, Accuracy : 71.8750\n",
      "Epoch : 7/10, Batch : 26/49, Loss : 0.6173, Accuracy : 71.6797\n",
      "epoch loss 0.30754452144976746\n",
      "epoch accuracy 0.71724\n",
      "Epoch : 8/10, Batch : 1/49, Loss : 0.6067, Accuracy : 73.0469\n",
      "Epoch : 8/10, Batch : 26/49, Loss : 0.6230, Accuracy : 68.1641\n",
      "epoch loss 0.30570304455216396\n",
      "epoch accuracy 0.72364\n",
      "Epoch : 9/10, Batch : 1/49, Loss : 0.5997, Accuracy : 73.0469\n",
      "Epoch : 9/10, Batch : 26/49, Loss : 0.6120, Accuracy : 72.4609\n",
      "epoch loss 0.30519830504643547\n",
      "epoch accuracy 0.72452\n",
      "Epoch : 10/10, Batch : 1/49, Loss : 0.6141, Accuracy : 71.4844\n",
      "Epoch : 10/10, Batch : 26/49, Loss : 0.6018, Accuracy : 72.6562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/97 [00:17<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss 0.30469172271256595\n",
      "epoch accuracy 0.72648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#we will call the supervised training function for binary classification\n",
    "#we will build the parameters for the function\n",
    "#model\n",
    "model = Classifier(2)\n",
    "model_save_path = moco_pretrained_dir + '_supervised_binary_classifier'\n",
    "#call the function\n",
    "model = supervised_training(model, binary_label, model_save_path, epochs= super_epochs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 2: Multi-class Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_class_label(ip):\n",
    "    l = []\n",
    "    for x in ip:\n",
    "        if x in [6,2]:\n",
    "            l.append(0)\n",
    "        if x in [3,5]:\n",
    "            l.append(1)\n",
    "        if x in [4,7]:\n",
    "            l.append(2)\n",
    "        if x in [1,9]:\n",
    "            l.append(3)\n",
    "        if x in [0,8]:\n",
    "            l.append(4)\n",
    "        \n",
    "    return torch.tensor(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "ConvNet\n",
      "ModuleList(\n",
      "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): Dropout(p=0.3, inplace=False)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): ReLU()\n",
      "  (8): Dropout(p=0.3, inplace=False)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (12): ReLU()\n",
      "  (13): Dropout(p=0.3, inplace=False)\n",
      "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "ConvNet\n",
      "ModuleList(\n",
      "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): Dropout(p=0.3, inplace=False)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): ReLU()\n",
      "  (8): Dropout(p=0.3, inplace=False)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (12): ReLU()\n",
      "  (13): Dropout(p=0.3, inplace=False)\n",
      "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "-----------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1/10, Batch : 1/49, Loss : 1.6116, Accuracy : 20.8984\n",
      "Epoch : 1/10, Batch : 26/49, Loss : 1.6121, Accuracy : 20.3125\n",
      "epoch loss 0.8131457948193108\n",
      "epoch accuracy 0.21064\n",
      "Epoch : 2/10, Batch : 1/49, Loss : 1.6084, Accuracy : 21.6797\n",
      "Epoch : 2/10, Batch : 26/49, Loss : 1.6124, Accuracy : 20.3125\n",
      "epoch loss 0.8115099385841605\n",
      "epoch accuracy 0.22304\n",
      "Epoch : 3/10, Batch : 1/49, Loss : 1.6057, Accuracy : 22.2656\n",
      "Epoch : 3/10, Batch : 26/49, Loss : 1.6039, Accuracy : 22.0703\n",
      "epoch loss 0.8101080139887702\n",
      "epoch accuracy 0.23328\n",
      "Epoch : 4/10, Batch : 1/49, Loss : 1.6001, Accuracy : 25.3906\n",
      "Epoch : 4/10, Batch : 26/49, Loss : 1.6045, Accuracy : 22.2656\n",
      "epoch loss 0.8087335775807961\n",
      "epoch accuracy 0.2402\n",
      "Epoch : 5/10, Batch : 1/49, Loss : 1.6002, Accuracy : 23.4375\n",
      "Epoch : 5/10, Batch : 26/49, Loss : 1.6017, Accuracy : 25.0000\n",
      "epoch loss 0.8075221162481406\n",
      "epoch accuracy 0.25032\n",
      "Epoch : 6/10, Batch : 1/49, Loss : 1.6014, Accuracy : 22.2656\n",
      "Epoch : 6/10, Batch : 26/49, Loss : 1.6010, Accuracy : 23.0469\n",
      "epoch loss 0.8067029063234624\n",
      "epoch accuracy 0.25288\n",
      "Epoch : 7/10, Batch : 1/49, Loss : 1.5988, Accuracy : 22.6562\n",
      "Epoch : 7/10, Batch : 26/49, Loss : 1.5984, Accuracy : 26.1719\n",
      "epoch loss 0.8063400824045398\n",
      "epoch accuracy 0.25644\n",
      "Epoch : 8/10, Batch : 1/49, Loss : 1.5934, Accuracy : 26.3672\n",
      "Epoch : 8/10, Batch : 26/49, Loss : 1.5881, Accuracy : 27.5391\n",
      "epoch loss 0.8055658770590713\n",
      "epoch accuracy 0.2582\n",
      "Epoch : 9/10, Batch : 1/49, Loss : 1.5956, Accuracy : 25.5859\n",
      "Epoch : 9/10, Batch : 26/49, Loss : 1.5902, Accuracy : 27.5391\n",
      "epoch loss 0.8053302248728644\n",
      "epoch accuracy 0.26212\n",
      "Epoch : 10/10, Batch : 1/49, Loss : 1.5964, Accuracy : 26.1719\n",
      "Epoch : 10/10, Batch : 26/49, Loss : 1.5943, Accuracy : 26.3672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/97 [00:17<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss 0.8052204318882263\n",
      "epoch accuracy 0.26144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#we will call the supervised training function for multi-classification\n",
    "#we will build the parameters for the function\n",
    "#model\n",
    "model = Classifier(5)\n",
    "model_save_path = moco_pretrained_dir + '_supervised_five_class_classifier'\n",
    "#call the function\n",
    "model = supervised_training(model, five_class_label, model_save_path, epochs= super_epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#good learning rate for 10 class is :1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10) \n[GCC 10.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "079402cc50f681fca3bc4b588c8594ae5b0127c6215ec7c89d21fdfb87f97274"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
